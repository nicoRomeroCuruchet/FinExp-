{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7270ebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for 29 stocks...\n",
      "YF deprecation warning: set proxy via new config function: yf.set_config(proxy=proxy)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (21924, 8)\n",
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n",
      "Calculating Covariance Matrices...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
    "from finrl import config_tickers\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Get Data (Fixed for WBA error)\n",
    "# ==============================================================================\n",
    "# WBA was delisted/taken private, so we remove it to prevent 404 errors\n",
    "ticker_list = [ticker for ticker in config_tickers.DOW_30_TICKER if ticker != 'WBA']\n",
    "\n",
    "print(f\"Downloading data for {len(ticker_list)} stocks...\")\n",
    "df = YahooDownloader(start_date='2020-01-01', \n",
    "                     end_date='2023-01-01', \n",
    "                     ticker_list=ticker_list).fetch_data()\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Add Technical Indicators & Covariance Matrix\n",
    "# ==============================================================================\n",
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list=['macd', 'rsi_30', 'cci_30', 'dx_30'],\n",
    "                     use_turbulence=True,\n",
    "                     user_defined_feature=False)\n",
    "\n",
    "df = fe.preprocess_data(df)\n",
    "\n",
    "# Sort to ensure alignment\n",
    "df = df.sort_values(['date','tic'], ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "\n",
    "cov_list = []\n",
    "return_list = []\n",
    "dates_with_cov = [] # We must track dates to map them back later\n",
    "lookback = 252 \n",
    "\n",
    "# Custom loop to generate covariance matrix for each day\n",
    "unique_dates = df.date.unique()\n",
    "\n",
    "print(\"Calculating Covariance Matrices...\")\n",
    "for i in range(lookback, len(unique_dates)):\n",
    "    current_date = unique_dates[i]\n",
    "    \n",
    "    # Slice lookback window\n",
    "    data_lookback = df.loc[i-lookback:i, :]\n",
    "    price_lookback = data_lookback.pivot_table(index='date', columns='tic', values='close')\n",
    "    \n",
    "    return_lookback = price_lookback.pct_change().dropna()\n",
    "    covs = return_lookback.cov().values \n",
    "    \n",
    "    cov_list.append(covs)\n",
    "    return_list.append(return_lookback)\n",
    "    dates_with_cov.append(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa6a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "# ==============================================================================\n",
    "# MODIFIED ENVIRONMENT: With FED Interest Rate + Turnover Penalty\n",
    "# ==============================================================================\n",
    "class StockPortfolioEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    A portfolio allocation environment for FinRL.\n",
    "    CUSTOMIZED: \n",
    "    1. Action Space = N Stocks + 1 Cash.\n",
    "    2. Reward = Log Returns - Transaction Costs (Turnover).\n",
    "    3. Cash earns Risk-Free Rate (e.g., 3.75%).\n",
    "    \"\"\"\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(self, df, stock_dim, hmax, initial_amount, transaction_cost_pct, \n",
    "                 reward_scaling, state_space, action_space, tech_indicator_list, \n",
    "                 turbulence_threshold=None, lookback=252, day=0, \n",
    "                 risk_free_rate=0.0375):\n",
    "        \n",
    "        self.day = day\n",
    "        self.lookback = lookback\n",
    "        self.df = df\n",
    "        self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.transaction_cost_pct = transaction_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "        self.risk_free_rate = risk_free_rate\n",
    "        \n",
    "        # Calculate Daily Risk-Free Return\n",
    "        self.daily_rf_rate = (1 + self.risk_free_rate) ** (1 / 252) - 1\n",
    "\n",
    "        # N+1 Action Space (Stocks + Cash)\n",
    "        self.action_space = spaces.Box(low=0, high=1, shape=(self.stock_dim + 1,))\n",
    "        \n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf,\n",
    "            high=np.inf,\n",
    "            shape=(self.state_space + len(self.tech_indicator_list), self.state_space),\n",
    "        )\n",
    "\n",
    "        self.data = self.df.loc[self.day, :]\n",
    "        self.covs = self.data[\"cov_list\"].values[0]\n",
    "        self.state = np.append(\n",
    "            np.array(self.covs),\n",
    "            [self.data[tech].values.tolist() for tech in self.tech_indicator_list],\n",
    "            axis=0,\n",
    "        )\n",
    "        self.terminal = False\n",
    "        self.portfolio_value = self.initial_amount\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        self.portfolio_return_memory = [0]\n",
    "        \n",
    "        # Inicializamos la memoria de acciones con pesos iguales\n",
    "        self.actions_memory = [[1 / (self.stock_dim + 1)] * (self.stock_dim + 1)]\n",
    "        self.date_memory = [self.data.date.unique()[0]]\n",
    "\n",
    "    def step(self, actions):\n",
    "        self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
    "\n",
    "        if self.terminal:\n",
    "            df = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df.columns = [\"daily_return\"]\n",
    "            if df[\"daily_return\"].std() != 0:\n",
    "                sharpe = (252**0.5) * df[\"daily_return\"].mean() / df[\"daily_return\"].std()\n",
    "                print(f\"Episode Finished. Sharpe: {sharpe:.2f}\")\n",
    "            return self.state, self.reward, self.terminal, False, {}\n",
    "\n",
    "        else:\n",
    "            # 1. Normalizar Pesos\n",
    "            weights = self.softmax_normalization(actions)\n",
    "            self.actions_memory.append(weights) # Guardamos los pesos actuales\n",
    "            \n",
    "            stock_weights = weights[:-1]\n",
    "            cash_weight = weights[-1]\n",
    "\n",
    "            last_day_memory = self.data\n",
    "\n",
    "            # 2. Avanzar el Día\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day, :]\n",
    "            \n",
    "            self.covs = self.data[\"cov_list\"].values[0]\n",
    "            self.state = np.append(\n",
    "                np.array(self.covs),\n",
    "                [self.data[tech].values.tolist() for tech in self.tech_indicator_list],\n",
    "                axis=0,\n",
    "            )\n",
    "\n",
    "            # 3. Calcular Retorno Financiero (Stocks + Cash Interest)\n",
    "            stock_returns = ((self.data.close.values / last_day_memory.close.values) - 1)\n",
    "            \n",
    "            weighted_stock_return = np.sum(stock_returns * stock_weights)\n",
    "            weighted_cash_return = cash_weight * self.daily_rf_rate\n",
    "            \n",
    "            portfolio_return = weighted_stock_return + weighted_cash_return\n",
    "            \n",
    "            # Actualizar Valor del Portafolio\n",
    "            new_portfolio_value = self.portfolio_value * (1 + portfolio_return)\n",
    "            self.portfolio_value = new_portfolio_value\n",
    "\n",
    "            self.portfolio_return_memory.append(portfolio_return)\n",
    "            self.date_memory.append(self.data.date.unique()[0])\n",
    "            self.asset_memory.append(new_portfolio_value)\n",
    "\n",
    "            # ==================================================================\n",
    "            # ### NUEVO: CÁLCULO DE COSTOS DE TRANSACCIÓN (TURNOVER)\n",
    "            # ==================================================================\n",
    "            \n",
    "            # Recuperamos los pesos de ayer (índice -2) y hoy (índice -1 o 'weights')\n",
    "            # Nota: Como hicimos .append(weights) al inicio del 'else', \n",
    "            # self.actions_memory[-1] son los actuales y [-2] los anteriores.\n",
    "            current_weights = weights\n",
    "            prev_weights = self.actions_memory[-2]\n",
    "            \n",
    "            # Turnover: Suma del valor absoluto de los cambios en cada activo\n",
    "            turnover = np.sum(np.abs(current_weights - prev_weights))\n",
    "            \n",
    "            # Costo: El turnover multiplicado por tu % de comisión\n",
    "            cost_penalty = turnover * self.transaction_cost_pct\n",
    "\n",
    "            # ==================================================================\n",
    "            # 4. CÁLCULO DE RECOMPENSA FINAL\n",
    "            # ==================================================================\n",
    "            \n",
    "            # Retorno Logarítmico Puro\n",
    "            log_return = np.log(new_portfolio_value / self.asset_memory[-2])\n",
    "            \n",
    "            # Recompensa = (Retorno - Costo) * Escala\n",
    "            # Restamos el costo ANTES de escalar para mantener la proporción\n",
    "            self.reward = (log_return - cost_penalty) * 100\n",
    "\n",
    "        return self.state, self.reward, self.terminal, False, {}\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.day = 0\n",
    "        self.data = self.df.loc[self.day, :]\n",
    "        self.covs = self.data[\"cov_list\"].values[0]\n",
    "        self.state = np.append(\n",
    "            np.array(self.covs),\n",
    "            [self.data[tech].values.tolist() for tech in self.tech_indicator_list],\n",
    "            axis=0,\n",
    "        )\n",
    "        self.portfolio_value = self.initial_amount\n",
    "        self.terminal = False\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory = [[1 / (self.stock_dim + 1)] * (self.stock_dim + 1)]\n",
    "        self.date_memory = [self.data.date.unique()[0]]\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        return self.state, {}\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        return self.state\n",
    "\n",
    "    def softmax_normalization(self, actions):\n",
    "        numerator = np.exp(actions)\n",
    "        denominator = np.sum(np.exp(actions))\n",
    "        return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a21c259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe ready. Index represents Day ID (0 to N).\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 3. THE FIX: Correct Indexing for Portfolio Env\n",
    "# ==============================================================================\n",
    "\n",
    "# Filter to valid dates\n",
    "df_portfolio = df[df.date.isin(dates_with_cov)].copy()\n",
    "\n",
    "# Map covariance\n",
    "cov_dict = dict(zip(dates_with_cov, cov_list))\n",
    "df_portfolio['cov_list'] = df_portfolio['date'].map(cov_dict)\n",
    "\n",
    "# CRITICAL FIX: Sort by date/ticker, THEN set index to factorized date\n",
    "# This ensures df.loc[0] returns ALL stocks for the first day\n",
    "df_portfolio = df_portfolio.sort_values(['date', 'tic'], ignore_index=True)\n",
    "df_portfolio.index = df_portfolio.date.factorize()[0]\n",
    "\n",
    "print(\"Dataframe ready. Index represents Day ID (0 to N).\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. Instantiate & Train\n",
    "# ==============================================================================\n",
    "stock_dimension = len(ticker_list)\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": stock_dimension, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": ['macd', 'rsi_30', 'cci_30', 'dx_30'], \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"risk_free_rate\": 0.0375, # 3.75%\n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df=df_portfolio, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba805949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PPO Training...\n",
      "{'ent_coef': 0.01}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Episode Finished. Sharpe: 0.45\n",
      "Episode Finished. Sharpe: 0.27\n",
      "Episode Finished. Sharpe: 0.34\n",
      "Episode Finished. Sharpe: 0.45\n",
      "-------------------------------------\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 504          |\n",
      "|    ep_rew_mean     | -13.5        |\n",
      "| time/              |              |\n",
      "|    fps             | 958          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 2            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.41568267  |\n",
      "|    reward_max      | 4.4054117    |\n",
      "|    reward_mean     | -0.024526345 |\n",
      "|    reward_min      | -4.225025    |\n",
      "-------------------------------------\n",
      "Episode Finished. Sharpe: 0.54\n",
      "Episode Finished. Sharpe: 0.46\n",
      "Episode Finished. Sharpe: 0.43\n",
      "Episode Finished. Sharpe: 0.42\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -12.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 733          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.03431279   |\n",
      "|    clip_fraction        | 0.332        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | -0.074       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.429       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0684      |\n",
      "|    reward               | -0.26521644  |\n",
      "|    reward_max           | 4.252026     |\n",
      "|    reward_mean          | -0.020639377 |\n",
      "|    reward_min           | -4.050465    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.24         |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.48\n",
      "Episode Finished. Sharpe: 0.29\n",
      "Episode Finished. Sharpe: 0.36\n",
      "Episode Finished. Sharpe: 0.41\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -12.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.03868857   |\n",
      "|    clip_fraction        | 0.379        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.7        |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.437       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0695      |\n",
      "|    reward               | 0.6087884    |\n",
      "|    reward_max           | 4.0553937    |\n",
      "|    reward_mean          | -0.025497718 |\n",
      "|    reward_min           | -4.0849714   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.575        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.45\n",
      "Episode Finished. Sharpe: 0.43\n",
      "Episode Finished. Sharpe: 0.42\n",
      "Episode Finished. Sharpe: 0.43\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -12.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 666          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.042029306  |\n",
      "|    clip_fraction        | 0.397        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.8        |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.397       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.069       |\n",
      "|    reward               | 0.25502813   |\n",
      "|    reward_max           | 4.0254126    |\n",
      "|    reward_mean          | -0.022843283 |\n",
      "|    reward_min           | -4.273955    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.337        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.60\n",
      "Episode Finished. Sharpe: 0.48\n",
      "Episode Finished. Sharpe: 0.46\n",
      "Episode Finished. Sharpe: 0.41\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -11.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 643          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.052597143  |\n",
      "|    clip_fraction        | 0.447        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.9        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.415       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.066       |\n",
      "|    reward               | 0.52664506   |\n",
      "|    reward_max           | 4.2184668    |\n",
      "|    reward_mean          | -0.020557687 |\n",
      "|    reward_min           | -3.9650624   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.235        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.44\n",
      "Episode Finished. Sharpe: 0.60\n",
      "Episode Finished. Sharpe: 0.29\n",
      "Episode Finished. Sharpe: 0.33\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -12          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.059913218  |\n",
      "|    clip_fraction        | 0.5          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43          |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.457       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0696      |\n",
      "|    reward               | 0.050842166  |\n",
      "|    reward_max           | 4.0035496    |\n",
      "|    reward_mean          | -0.025632886 |\n",
      "|    reward_min           | -4.0501056   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.188        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.33\n",
      "Episode Finished. Sharpe: 0.64\n",
      "Episode Finished. Sharpe: 0.58\n",
      "Episode Finished. Sharpe: 0.39\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -11.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.058602322  |\n",
      "|    clip_fraction        | 0.467        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.1        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.45        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0699      |\n",
      "|    reward               | -0.8610421   |\n",
      "|    reward_max           | 3.9112067    |\n",
      "|    reward_mean          | -0.019643176 |\n",
      "|    reward_min           | -4.075953    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 0.21         |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.53\n",
      "Episode Finished. Sharpe: 0.50\n",
      "Episode Finished. Sharpe: 0.43\n",
      "Episode Finished. Sharpe: 0.38\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -11.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 628          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.06692088   |\n",
      "|    clip_fraction        | 0.508        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.3        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.415       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0751      |\n",
      "|    reward               | -0.26263708  |\n",
      "|    reward_max           | 3.990312     |\n",
      "|    reward_mean          | -0.020350626 |\n",
      "|    reward_min           | -4.0576596   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.201        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.43\n",
      "Episode Finished. Sharpe: 0.58\n",
      "Episode Finished. Sharpe: 0.26\n",
      "Episode Finished. Sharpe: 0.68\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -11.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 625          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.079996586  |\n",
      "|    clip_fraction        | 0.544        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.4        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.467       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0672      |\n",
      "|    reward               | -1.2307132   |\n",
      "|    reward_max           | 4.4360476    |\n",
      "|    reward_mean          | -0.022561224 |\n",
      "|    reward_min           | -4.176012    |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.137        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.57\n",
      "Episode Finished. Sharpe: 0.51\n",
      "Episode Finished. Sharpe: 0.51\n",
      "Episode Finished. Sharpe: 0.44\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -11.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 618          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.06788018   |\n",
      "|    clip_fraction        | 0.513        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.5        |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.444       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0687      |\n",
      "|    reward               | 0.10064588   |\n",
      "|    reward_max           | 3.909809     |\n",
      "|    reward_mean          | -0.019031098 |\n",
      "|    reward_min           | -4.0899115   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.187        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.43\n",
      "Episode Finished. Sharpe: 0.42\n",
      "Episode Finished. Sharpe: 0.48\n",
      "Episode Finished. Sharpe: 0.49\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -11.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08255988   |\n",
      "|    clip_fraction        | 0.55         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.6        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.47        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0688      |\n",
      "|    reward               | 0.53650355   |\n",
      "|    reward_max           | 3.764528     |\n",
      "|    reward_mean          | -0.025530854 |\n",
      "|    reward_min           | -4.14121     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.117        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.48\n",
      "Episode Finished. Sharpe: 0.50\n",
      "Episode Finished. Sharpe: 0.42\n",
      "Episode Finished. Sharpe: 0.51\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -11.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 619          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08079012   |\n",
      "|    clip_fraction        | 0.533        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.6        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.471       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0666      |\n",
      "|    reward               | -0.51993835  |\n",
      "|    reward_max           | 3.7493556    |\n",
      "|    reward_mean          | -0.021556467 |\n",
      "|    reward_min           | -4.085285    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.123        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.60\n",
      "Episode Finished. Sharpe: 0.51\n",
      "Episode Finished. Sharpe: 0.46\n",
      "Episode Finished. Sharpe: 0.43\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -11.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 618          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.07866474   |\n",
      "|    clip_fraction        | 0.533        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.7        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.475       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.071       |\n",
      "|    reward               | -2.887684    |\n",
      "|    reward_max           | 4.086773     |\n",
      "|    reward_mean          | -0.021562153 |\n",
      "|    reward_min           | -4.077681    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 0.139        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.31\n",
      "Episode Finished. Sharpe: 0.55\n",
      "Episode Finished. Sharpe: 0.35\n",
      "Episode Finished. Sharpe: 0.40\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -11.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.07299717   |\n",
      "|    clip_fraction        | 0.51         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.8        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.465       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0686      |\n",
      "|    reward               | -0.09902969  |\n",
      "|    reward_max           | 4.1133857    |\n",
      "|    reward_mean          | -0.029361596 |\n",
      "|    reward_min           | -4.1399636   |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.15         |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.43\n",
      "Episode Finished. Sharpe: 0.49\n",
      "Episode Finished. Sharpe: 0.57\n",
      "Episode Finished. Sharpe: 0.39\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -11.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.07323133   |\n",
      "|    clip_fraction        | 0.515        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -43.9        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.458       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0698      |\n",
      "|    reward               | -1.609398    |\n",
      "|    reward_max           | 4.3391843    |\n",
      "|    reward_mean          | -0.014620018 |\n",
      "|    reward_min           | -4.1135917   |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.15         |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.40\n",
      "Episode Finished. Sharpe: 0.35\n",
      "Episode Finished. Sharpe: 0.59\n",
      "Episode Finished. Sharpe: 0.49\n",
      "Episode Finished. Sharpe: 0.36\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -11.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.081893094  |\n",
      "|    clip_fraction        | 0.53         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44          |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.483       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0666      |\n",
      "|    reward               | 0.04343428   |\n",
      "|    reward_max           | 4.091092     |\n",
      "|    reward_mean          | -0.023107711 |\n",
      "|    reward_min           | -4.087531    |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 0.0965       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.45\n",
      "Episode Finished. Sharpe: 0.62\n",
      "Episode Finished. Sharpe: 0.41\n",
      "Episode Finished. Sharpe: 0.49\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -11.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 615          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08577973   |\n",
      "|    clip_fraction        | 0.535        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.1        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.474       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0723      |\n",
      "|    reward               | -0.37912792  |\n",
      "|    reward_max           | 4.1921678    |\n",
      "|    reward_mean          | -0.020199306 |\n",
      "|    reward_min           | -3.9441054   |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.115        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.50\n",
      "Episode Finished. Sharpe: 0.54\n",
      "Episode Finished. Sharpe: 0.44\n",
      "Episode Finished. Sharpe: 0.54\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -11.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08439025   |\n",
      "|    clip_fraction        | 0.526        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.3        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.512       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0669      |\n",
      "|    reward               | 0.4516786    |\n",
      "|    reward_max           | 3.9729805    |\n",
      "|    reward_mean          | -0.014328405 |\n",
      "|    reward_min           | -3.9354763   |\n",
      "|    std                  | 1.06         |\n",
      "|    value_loss           | 0.116        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.58\n",
      "Episode Finished. Sharpe: 0.47\n",
      "Episode Finished. Sharpe: 0.54\n",
      "Episode Finished. Sharpe: 0.59\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -10.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 615          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.088561974  |\n",
      "|    clip_fraction        | 0.545        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.4        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.492       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0694      |\n",
      "|    reward               | 0.05502158   |\n",
      "|    reward_max           | 4.0800257    |\n",
      "|    reward_mean          | -0.016471123 |\n",
      "|    reward_min           | -4.0742264   |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.117        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.56\n",
      "Episode Finished. Sharpe: 0.54\n",
      "Episode Finished. Sharpe: 0.57\n",
      "Episode Finished. Sharpe: 0.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -10.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 615          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.079969294  |\n",
      "|    clip_fraction        | 0.515        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -44.5        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.459       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0708      |\n",
      "|    reward               | -1.8572139   |\n",
      "|    reward_max           | 4.3170524    |\n",
      "|    reward_mean          | -0.015606346 |\n",
      "|    reward_min           | -3.9013505   |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 0.117        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.39\n",
      "Episode Finished. Sharpe: 0.62\n",
      "Episode Finished. Sharpe: 0.45\n",
      "Episode Finished. Sharpe: 0.65\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | -10.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08333777  |\n",
      "|    clip_fraction        | 0.5         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.6       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.428      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0625     |\n",
      "|    reward               | -0.1142237  |\n",
      "|    reward_max           | 3.9074569   |\n",
      "|    reward_mean          | -0.01524057 |\n",
      "|    reward_min           | -3.984434   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.0942      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.54\n",
      "Episode Finished. Sharpe: 0.62\n",
      "Episode Finished. Sharpe: 0.57\n",
      "Episode Finished. Sharpe: 0.59\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | -10.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 610         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08208144  |\n",
      "|    clip_fraction        | 0.521       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -44.8       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.494      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0651     |\n",
      "|    reward               | -0.33460492 |\n",
      "|    reward_max           | 4.1823163   |\n",
      "|    reward_mean          | -0.01595791 |\n",
      "|    reward_min           | -3.999958   |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.50\n",
      "Episode Finished. Sharpe: 0.51\n",
      "Episode Finished. Sharpe: 0.56\n",
      "Episode Finished. Sharpe: 0.57\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | -10.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 605         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.080345705 |\n",
      "|    clip_fraction        | 0.517       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45         |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.539      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0666     |\n",
      "|    reward               | 1.5709436   |\n",
      "|    reward_max           | 4.2017727   |\n",
      "|    reward_mean          | -0.0165234  |\n",
      "|    reward_min           | -3.971359   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.58\n",
      "Episode Finished. Sharpe: 0.58\n",
      "Episode Finished. Sharpe: 0.69\n",
      "Episode Finished. Sharpe: 0.45\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -10.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 600          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08848691   |\n",
      "|    clip_fraction        | 0.52         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.1        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.513       |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0599      |\n",
      "|    reward               | -0.8530166   |\n",
      "|    reward_max           | 3.8648922    |\n",
      "|    reward_mean          | -0.014148001 |\n",
      "|    reward_min           | -4.08021     |\n",
      "|    std                  | 1.09         |\n",
      "|    value_loss           | 0.11         |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.54\n",
      "Episode Finished. Sharpe: 0.62\n",
      "Episode Finished. Sharpe: 0.55\n",
      "Episode Finished. Sharpe: 0.60\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -10.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 597          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08499618   |\n",
      "|    clip_fraction        | 0.517        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.2        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.503       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0707      |\n",
      "|    reward               | -2.5970218   |\n",
      "|    reward_max           | 4.085916     |\n",
      "|    reward_mean          | -0.018238818 |\n",
      "|    reward_min           | -4.047539    |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.096        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.53\n",
      "Episode Finished. Sharpe: 0.64\n",
      "Episode Finished. Sharpe: 0.72\n",
      "Episode Finished. Sharpe: 0.61\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -9.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 594          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08196239   |\n",
      "|    clip_fraction        | 0.514        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.4        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.49        |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.0707      |\n",
      "|    reward               | -0.9836505   |\n",
      "|    reward_max           | 4.0831285    |\n",
      "|    reward_mean          | -0.008178267 |\n",
      "|    reward_min           | -4.1282997   |\n",
      "|    std                  | 1.1          |\n",
      "|    value_loss           | 0.14         |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.55\n",
      "Episode Finished. Sharpe: 0.39\n",
      "Episode Finished. Sharpe: 0.56\n",
      "Episode Finished. Sharpe: 0.64\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | -9.79       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.090972014 |\n",
      "|    clip_fraction        | 0.536       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -45.5       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.501      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0668     |\n",
      "|    reward               | 0.669664    |\n",
      "|    reward_max           | 4.108558    |\n",
      "|    reward_mean          | -0.01809626 |\n",
      "|    reward_min           | -4.007139   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.73\n",
      "Episode Finished. Sharpe: 0.52\n",
      "Episode Finished. Sharpe: 0.67\n",
      "Episode Finished. Sharpe: 0.66\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -9.44        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 589          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08050529   |\n",
      "|    clip_fraction        | 0.515        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.6        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.481       |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0651      |\n",
      "|    reward               | 0.22837834   |\n",
      "|    reward_max           | 4.1859093    |\n",
      "|    reward_mean          | -0.011876594 |\n",
      "|    reward_min           | -3.9744735   |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.121        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.75\n",
      "Episode Finished. Sharpe: 0.64\n",
      "Episode Finished. Sharpe: 0.60\n",
      "Episode Finished. Sharpe: 0.56\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -9.23        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 588          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 100          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.085664734  |\n",
      "|    clip_fraction        | 0.509        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.7        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.518       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0717      |\n",
      "|    reward               | 0.5632528    |\n",
      "|    reward_max           | 4.382669     |\n",
      "|    reward_mean          | -0.012804712 |\n",
      "|    reward_min           | -4.0849524   |\n",
      "|    std                  | 1.11         |\n",
      "|    value_loss           | 0.135        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.68\n",
      "Episode Finished. Sharpe: 0.77\n",
      "Episode Finished. Sharpe: 0.70\n",
      "Episode Finished. Sharpe: 0.47\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -8.97        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 585          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.07270085   |\n",
      "|    clip_fraction        | 0.49         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.8        |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.489       |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.063       |\n",
      "|    reward               | 1.2184982    |\n",
      "|    reward_max           | 3.921233     |\n",
      "|    reward_mean          | -0.011210501 |\n",
      "|    reward_min           | -3.9614303   |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 0.117        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.59\n",
      "Episode Finished. Sharpe: 0.72\n",
      "Episode Finished. Sharpe: 0.67\n",
      "Episode Finished. Sharpe: 0.65\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -8.62        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 583          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08596899   |\n",
      "|    clip_fraction        | 0.524        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -45.9        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.505       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0665      |\n",
      "|    reward               | 0.449559     |\n",
      "|    reward_max           | 4.2173724    |\n",
      "|    reward_mean          | -0.006957562 |\n",
      "|    reward_min           | -4.044196    |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 0.142        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.53\n",
      "Episode Finished. Sharpe: 0.56\n",
      "Episode Finished. Sharpe: 0.58\n",
      "Episode Finished. Sharpe: 0.65\n",
      "Episode Finished. Sharpe: 0.67\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -8.49        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 584          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.09373468   |\n",
      "|    clip_fraction        | 0.523        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46          |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.464       |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0685      |\n",
      "|    reward               | -0.38482416  |\n",
      "|    reward_max           | 3.9892719    |\n",
      "|    reward_mean          | -0.011819287 |\n",
      "|    reward_min           | -4.0138803   |\n",
      "|    std                  | 1.12         |\n",
      "|    value_loss           | 0.106        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.73\n",
      "Episode Finished. Sharpe: 0.71\n",
      "Episode Finished. Sharpe: 0.66\n",
      "Episode Finished. Sharpe: 0.73\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -8.17         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 585           |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 115           |\n",
      "|    total_timesteps      | 67584         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.09063133    |\n",
      "|    clip_fraction        | 0.508         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -46.1         |\n",
      "|    explained_variance   | 0.993         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.521        |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | -0.064        |\n",
      "|    reward               | 0.7316209     |\n",
      "|    reward_max           | 3.8738925     |\n",
      "|    reward_mean          | -0.0037307583 |\n",
      "|    reward_min           | -4.2102737    |\n",
      "|    std                  | 1.13          |\n",
      "|    value_loss           | 0.0978        |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.69\n",
      "Episode Finished. Sharpe: 0.74\n",
      "Episode Finished. Sharpe: 0.76\n",
      "Episode Finished. Sharpe: 0.68\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -7.91        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 586          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 118          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08562437   |\n",
      "|    clip_fraction        | 0.507        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46.2        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.484       |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0682      |\n",
      "|    reward               | -0.34872684  |\n",
      "|    reward_max           | 4.1307044    |\n",
      "|    reward_mean          | -0.005110085 |\n",
      "|    reward_min           | -4.202918    |\n",
      "|    std                  | 1.13         |\n",
      "|    value_loss           | 0.12         |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.60\n",
      "Episode Finished. Sharpe: 0.60\n",
      "Episode Finished. Sharpe: 0.75\n",
      "Episode Finished. Sharpe: 0.78\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -7.61        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 587          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.09112476   |\n",
      "|    clip_fraction        | 0.517        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46.4        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.508       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0615      |\n",
      "|    reward               | -0.260974    |\n",
      "|    reward_max           | 4.1620054    |\n",
      "|    reward_mean          | -0.007029866 |\n",
      "|    reward_min           | -4.0376654   |\n",
      "|    std                  | 1.14         |\n",
      "|    value_loss           | 0.0918       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.73\n",
      "Episode Finished. Sharpe: 0.80\n",
      "Episode Finished. Sharpe: 0.73\n",
      "Episode Finished. Sharpe: 0.67\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -7.29         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 588           |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 125           |\n",
      "|    total_timesteps      | 73728         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.10611351    |\n",
      "|    clip_fraction        | 0.544         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -46.5         |\n",
      "|    explained_variance   | 0.993         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.51         |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | -0.0568       |\n",
      "|    reward               | 0.41180012    |\n",
      "|    reward_max           | 4.091215      |\n",
      "|    reward_mean          | -0.0039085415 |\n",
      "|    reward_min           | -3.9961715    |\n",
      "|    std                  | 1.15          |\n",
      "|    value_loss           | 0.0961        |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.60\n",
      "Episode Finished. Sharpe: 0.70\n",
      "Episode Finished. Sharpe: 0.63\n",
      "Episode Finished. Sharpe: 0.69\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -7.11        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 589          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.088275954  |\n",
      "|    clip_fraction        | 0.492        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -46.7        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.524       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.067       |\n",
      "|    reward               | -0.947448    |\n",
      "|    reward_max           | 4.130801     |\n",
      "|    reward_mean          | -0.011151399 |\n",
      "|    reward_min           | -4.1291494   |\n",
      "|    std                  | 1.15         |\n",
      "|    value_loss           | 0.106        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.76\n",
      "Episode Finished. Sharpe: 0.64\n",
      "Episode Finished. Sharpe: 0.56\n",
      "Episode Finished. Sharpe: 0.85\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -6.77         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 590           |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 131           |\n",
      "|    total_timesteps      | 77824         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.091967374   |\n",
      "|    clip_fraction        | 0.509         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -46.8         |\n",
      "|    explained_variance   | 0.992         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.525        |\n",
      "|    n_updates            | 370           |\n",
      "|    policy_gradient_loss | -0.0653       |\n",
      "|    reward               | 0.98049814    |\n",
      "|    reward_max           | 4.1013594     |\n",
      "|    reward_mean          | -0.0045624133 |\n",
      "|    reward_min           | -4.0536704    |\n",
      "|    std                  | 1.16          |\n",
      "|    value_loss           | 0.103         |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.64\n",
      "Episode Finished. Sharpe: 0.79\n",
      "Episode Finished. Sharpe: 0.78\n",
      "Episode Finished. Sharpe: 0.66\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -6.37        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 591          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 135          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08517448   |\n",
      "|    clip_fraction        | 0.475        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47          |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.526       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0685      |\n",
      "|    reward               | -0.13009407  |\n",
      "|    reward_max           | 4.0219584    |\n",
      "|    reward_mean          | -0.006211881 |\n",
      "|    reward_min           | -4.150826    |\n",
      "|    std                  | 1.16         |\n",
      "|    value_loss           | 0.136        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.72\n",
      "Episode Finished. Sharpe: 0.75\n",
      "Episode Finished. Sharpe: 0.72\n",
      "Episode Finished. Sharpe: 0.80\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -5.96         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 591           |\n",
      "|    iterations           | 40            |\n",
      "|    time_elapsed         | 138           |\n",
      "|    total_timesteps      | 81920         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.08265019    |\n",
      "|    clip_fraction        | 0.499         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -47.1         |\n",
      "|    explained_variance   | 0.994         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.552        |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.0662       |\n",
      "|    reward               | 1.1960998     |\n",
      "|    reward_max           | 4.3540044     |\n",
      "|    reward_mean          | -0.0029706582 |\n",
      "|    reward_min           | -4.1431694    |\n",
      "|    std                  | 1.17          |\n",
      "|    value_loss           | 0.0918        |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.65\n",
      "Episode Finished. Sharpe: 0.77\n",
      "Episode Finished. Sharpe: 0.63\n",
      "Episode Finished. Sharpe: 0.70\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -5.68        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 592          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.09188451   |\n",
      "|    clip_fraction        | 0.5          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.2        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.544       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0601      |\n",
      "|    reward               | 1.2794821    |\n",
      "|    reward_max           | 4.149074     |\n",
      "|    reward_mean          | -0.006345504 |\n",
      "|    reward_min           | -3.9256651   |\n",
      "|    std                  | 1.17         |\n",
      "|    value_loss           | 0.0814       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.76\n",
      "Episode Finished. Sharpe: 0.83\n",
      "Episode Finished. Sharpe: 0.80\n",
      "Episode Finished. Sharpe: 0.75\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -5.32         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 592           |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 145           |\n",
      "|    total_timesteps      | 86016         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.08964772    |\n",
      "|    clip_fraction        | 0.487         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -47.3         |\n",
      "|    explained_variance   | 0.993         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.527        |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | -0.0681       |\n",
      "|    reward               | 0.08564992    |\n",
      "|    reward_max           | 4.0385904     |\n",
      "|    reward_mean          | -0.0046859393 |\n",
      "|    reward_min           | -4.0893607    |\n",
      "|    std                  | 1.17          |\n",
      "|    value_loss           | 0.102         |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.70\n",
      "Episode Finished. Sharpe: 0.79\n",
      "Episode Finished. Sharpe: 0.70\n",
      "Episode Finished. Sharpe: 0.70\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -5.06        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 592          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 148          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.10046336   |\n",
      "|    clip_fraction        | 0.515        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.4        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.516       |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0611      |\n",
      "|    reward               | 0.024136538  |\n",
      "|    reward_max           | 3.7066143    |\n",
      "|    reward_mean          | -0.011911889 |\n",
      "|    reward_min           | -3.925858    |\n",
      "|    std                  | 1.18         |\n",
      "|    value_loss           | 0.0913       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.59\n",
      "Episode Finished. Sharpe: 0.64\n",
      "Episode Finished. Sharpe: 0.89\n",
      "Episode Finished. Sharpe: 0.75\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 504            |\n",
      "|    ep_rew_mean          | -4.84          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 592            |\n",
      "|    iterations           | 44             |\n",
      "|    time_elapsed         | 151            |\n",
      "|    total_timesteps      | 90112          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.09073961     |\n",
      "|    clip_fraction        | 0.499          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -47.5          |\n",
      "|    explained_variance   | 0.994          |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | -0.511         |\n",
      "|    n_updates            | 430            |\n",
      "|    policy_gradient_loss | -0.0639        |\n",
      "|    reward               | -0.19966663    |\n",
      "|    reward_max           | 4.047475       |\n",
      "|    reward_mean          | -0.00025959406 |\n",
      "|    reward_min           | -3.964558      |\n",
      "|    std                  | 1.18           |\n",
      "|    value_loss           | 0.0826         |\n",
      "--------------------------------------------\n",
      "Episode Finished. Sharpe: 0.72\n",
      "Episode Finished. Sharpe: 0.60\n",
      "Episode Finished. Sharpe: 0.75\n",
      "Episode Finished. Sharpe: 0.57\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | -4.67       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09238352  |\n",
      "|    clip_fraction        | 0.525       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -47.6       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.484      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0661     |\n",
      "|    reward               | -1.2437625  |\n",
      "|    reward_max           | 4.0444236   |\n",
      "|    reward_mean          | -0.01170136 |\n",
      "|    reward_min           | -3.9555886  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.73\n",
      "Episode Finished. Sharpe: 0.77\n",
      "Episode Finished. Sharpe: 0.77\n",
      "Episode Finished. Sharpe: 0.74\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -4.44         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 593           |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 158           |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.10919896    |\n",
      "|    clip_fraction        | 0.504         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -47.7         |\n",
      "|    explained_variance   | 0.992         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.504        |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -0.063        |\n",
      "|    reward               | -0.5618815    |\n",
      "|    reward_max           | 4.130294      |\n",
      "|    reward_mean          | -0.0028416237 |\n",
      "|    reward_min           | -3.9333649    |\n",
      "|    std                  | 1.19          |\n",
      "|    value_loss           | 0.0998        |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.73\n",
      "Episode Finished. Sharpe: 0.78\n",
      "Episode Finished. Sharpe: 0.63\n",
      "Episode Finished. Sharpe: 0.90\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -4.19         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 594           |\n",
      "|    iterations           | 47            |\n",
      "|    time_elapsed         | 162           |\n",
      "|    total_timesteps      | 96256         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.09522183    |\n",
      "|    clip_fraction        | 0.504         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -47.8         |\n",
      "|    explained_variance   | 0.994         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.555        |\n",
      "|    n_updates            | 460           |\n",
      "|    policy_gradient_loss | -0.0625       |\n",
      "|    reward               | 0.18898934    |\n",
      "|    reward_max           | 4.171674      |\n",
      "|    reward_mean          | -0.0012549441 |\n",
      "|    reward_min           | -4.071192     |\n",
      "|    std                  | 1.19          |\n",
      "|    value_loss           | 0.0791        |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.71\n",
      "Episode Finished. Sharpe: 0.69\n",
      "Episode Finished. Sharpe: 0.89\n",
      "Episode Finished. Sharpe: 0.65\n",
      "Episode Finished. Sharpe: 0.79\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -3.89        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 594          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 165          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.085084826  |\n",
      "|    clip_fraction        | 0.478        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -47.9        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.483       |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0634      |\n",
      "|    reward               | 0.30036733   |\n",
      "|    reward_max           | 4.2129674    |\n",
      "|    reward_mean          | -0.001367332 |\n",
      "|    reward_min           | -3.8025491   |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 0.0975       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.79\n",
      "Episode Finished. Sharpe: 0.77\n",
      "Episode Finished. Sharpe: 0.76\n",
      "Episode Finished. Sharpe: 0.78\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -3.62        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 594          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.08713812   |\n",
      "|    clip_fraction        | 0.486        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48          |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.501       |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0618      |\n",
      "|    reward               | 0.14493679   |\n",
      "|    reward_max           | 4.2290134    |\n",
      "|    reward_mean          | 0.0004063203 |\n",
      "|    reward_min           | -3.9384556   |\n",
      "|    std                  | 1.2          |\n",
      "|    value_loss           | 0.0886       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.77\n",
      "Episode Finished. Sharpe: 0.79\n",
      "Episode Finished. Sharpe: 0.81\n",
      "Episode Finished. Sharpe: 0.83\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -3.33        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 595          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 172          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.09552474   |\n",
      "|    clip_fraction        | 0.509        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.2        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.52        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0639      |\n",
      "|    reward               | -0.13966739  |\n",
      "|    reward_max           | 4.186272     |\n",
      "|    reward_mean          | 0.0022894037 |\n",
      "|    reward_min           | -3.968791    |\n",
      "|    std                  | 1.21         |\n",
      "|    value_loss           | 0.0613       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.79\n",
      "Episode Finished. Sharpe: 0.71\n",
      "Episode Finished. Sharpe: 0.75\n",
      "Episode Finished. Sharpe: 0.79\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | -3.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08441622  |\n",
      "|    clip_fraction        | 0.503       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -48.3       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.516      |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0734     |\n",
      "|    reward               | 0.76868266  |\n",
      "|    reward_max           | 4.2340517   |\n",
      "|    reward_mean          | -0.00310253 |\n",
      "|    reward_min           | -4.0456076  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.85\n",
      "Episode Finished. Sharpe: 0.71\n",
      "Episode Finished. Sharpe: 0.62\n",
      "Episode Finished. Sharpe: 0.70\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -2.94         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 596           |\n",
      "|    iterations           | 52            |\n",
      "|    time_elapsed         | 178           |\n",
      "|    total_timesteps      | 106496        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0923125     |\n",
      "|    clip_fraction        | 0.498         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.3         |\n",
      "|    explained_variance   | 0.993         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.531        |\n",
      "|    n_updates            | 510           |\n",
      "|    policy_gradient_loss | -0.0575       |\n",
      "|    reward               | 0.45951033    |\n",
      "|    reward_max           | 4.042922      |\n",
      "|    reward_mean          | -0.0046513095 |\n",
      "|    reward_min           | -3.996026     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 0.117         |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.82\n",
      "Episode Finished. Sharpe: 0.83\n",
      "Episode Finished. Sharpe: 0.80\n",
      "Episode Finished. Sharpe: 0.80\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -2.78         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 596           |\n",
      "|    iterations           | 53            |\n",
      "|    time_elapsed         | 181           |\n",
      "|    total_timesteps      | 108544        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.094916776   |\n",
      "|    clip_fraction        | 0.491         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.4         |\n",
      "|    explained_variance   | 0.993         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.535        |\n",
      "|    n_updates            | 520           |\n",
      "|    policy_gradient_loss | -0.0616       |\n",
      "|    reward               | -0.13855886   |\n",
      "|    reward_max           | 4.424073      |\n",
      "|    reward_mean          | -0.0009166132 |\n",
      "|    reward_min           | -4.060811     |\n",
      "|    std                  | 1.22          |\n",
      "|    value_loss           | 0.101         |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.78\n",
      "Episode Finished. Sharpe: 0.73\n",
      "Episode Finished. Sharpe: 0.66\n",
      "Episode Finished. Sharpe: 0.71\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -2.68        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 596          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.10318132   |\n",
      "|    clip_fraction        | 0.508        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -48.5        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.507       |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0577      |\n",
      "|    reward               | -0.21474369  |\n",
      "|    reward_max           | 4.157819     |\n",
      "|    reward_mean          | -0.003273091 |\n",
      "|    reward_min           | -3.8648348   |\n",
      "|    std                  | 1.22         |\n",
      "|    value_loss           | 0.0966       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.93\n",
      "Episode Finished. Sharpe: 0.62\n",
      "Episode Finished. Sharpe: 0.78\n",
      "Episode Finished. Sharpe: 0.82\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -2.46         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 597           |\n",
      "|    iterations           | 55            |\n",
      "|    time_elapsed         | 188           |\n",
      "|    total_timesteps      | 112640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.098888      |\n",
      "|    clip_fraction        | 0.495         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.6         |\n",
      "|    explained_variance   | 0.993         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.558        |\n",
      "|    n_updates            | 540           |\n",
      "|    policy_gradient_loss | -0.0642       |\n",
      "|    reward               | 0.8503262     |\n",
      "|    reward_max           | 4.223183      |\n",
      "|    reward_mean          | -0.0009527791 |\n",
      "|    reward_min           | -3.9063218    |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 0.0877        |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.73\n",
      "Episode Finished. Sharpe: 0.71\n",
      "Episode Finished. Sharpe: 0.74\n",
      "Episode Finished. Sharpe: 0.81\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -2.27         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 597           |\n",
      "|    iterations           | 56            |\n",
      "|    time_elapsed         | 191           |\n",
      "|    total_timesteps      | 114688        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.09301331    |\n",
      "|    clip_fraction        | 0.477         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.7         |\n",
      "|    explained_variance   | 0.993         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.537        |\n",
      "|    n_updates            | 550           |\n",
      "|    policy_gradient_loss | -0.0669       |\n",
      "|    reward               | -1.3865294    |\n",
      "|    reward_max           | 4.290132      |\n",
      "|    reward_mean          | -0.0028522504 |\n",
      "|    reward_min           | -3.916818     |\n",
      "|    std                  | 1.23          |\n",
      "|    value_loss           | 0.106         |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.84\n",
      "Episode Finished. Sharpe: 0.71\n",
      "Episode Finished. Sharpe: 0.82\n",
      "Episode Finished. Sharpe: 0.71\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -2.12         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 598           |\n",
      "|    iterations           | 57            |\n",
      "|    time_elapsed         | 195           |\n",
      "|    total_timesteps      | 116736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.089772716   |\n",
      "|    clip_fraction        | 0.507         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.8         |\n",
      "|    explained_variance   | 0.994         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.551        |\n",
      "|    n_updates            | 560           |\n",
      "|    policy_gradient_loss | -0.0666       |\n",
      "|    reward               | 0.7785849     |\n",
      "|    reward_max           | 4.4733043     |\n",
      "|    reward_mean          | -0.0031216566 |\n",
      "|    reward_min           | -3.980544     |\n",
      "|    std                  | 1.24          |\n",
      "|    value_loss           | 0.0978        |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.77\n",
      "Episode Finished. Sharpe: 0.78\n",
      "Episode Finished. Sharpe: 0.86\n",
      "Episode Finished. Sharpe: 0.80\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -1.98         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 598           |\n",
      "|    iterations           | 58            |\n",
      "|    time_elapsed         | 198           |\n",
      "|    total_timesteps      | 118784        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.09338683    |\n",
      "|    clip_fraction        | 0.492         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -48.9         |\n",
      "|    explained_variance   | 0.992         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.519        |\n",
      "|    n_updates            | 570           |\n",
      "|    policy_gradient_loss | -0.0604       |\n",
      "|    reward               | 1.4656224     |\n",
      "|    reward_max           | 4.1997657     |\n",
      "|    reward_mean          | -0.0024307235 |\n",
      "|    reward_min           | -4.03659      |\n",
      "|    std                  | 1.24          |\n",
      "|    value_loss           | 0.106         |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.77\n",
      "Episode Finished. Sharpe: 0.77\n",
      "Episode Finished. Sharpe: 0.68\n",
      "Episode Finished. Sharpe: 0.89\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 504           |\n",
      "|    ep_rew_mean          | -1.86         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 598           |\n",
      "|    iterations           | 59            |\n",
      "|    time_elapsed         | 201           |\n",
      "|    total_timesteps      | 120832        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.09228502    |\n",
      "|    clip_fraction        | 0.496         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -49.1         |\n",
      "|    explained_variance   | 0.995         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.485        |\n",
      "|    n_updates            | 580           |\n",
      "|    policy_gradient_loss | -0.0617       |\n",
      "|    reward               | -0.58575535   |\n",
      "|    reward_max           | 4.397624      |\n",
      "|    reward_mean          | -0.0042182994 |\n",
      "|    reward_min           | -4.1471543    |\n",
      "|    std                  | 1.25          |\n",
      "|    value_loss           | 0.0877        |\n",
      "-------------------------------------------\n",
      "Episode Finished. Sharpe: 0.89\n",
      "Episode Finished. Sharpe: 0.82\n",
      "Episode Finished. Sharpe: 0.83\n",
      "Episode Finished. Sharpe: 0.86\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | -1.69       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 598         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10520215  |\n",
      "|    clip_fraction        | 0.494       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.2       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.533      |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0607     |\n",
      "|    reward               | 0.5622616   |\n",
      "|    reward_max           | 4.3474617   |\n",
      "|    reward_mean          | 0.007141709 |\n",
      "|    reward_min           | -3.9464593  |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 0.0976      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.85\n",
      "Episode Finished. Sharpe: 0.68\n",
      "Episode Finished. Sharpe: 0.85\n",
      "Episode Finished. Sharpe: 0.70\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -1.59        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 599          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 208          |\n",
      "|    total_timesteps      | 124928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.10562923   |\n",
      "|    clip_fraction        | 0.513        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.3        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.584       |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0584      |\n",
      "|    reward               | -1.9344549   |\n",
      "|    reward_max           | 4.5322595    |\n",
      "|    reward_mean          | -0.011235589 |\n",
      "|    reward_min           | -4.0427847   |\n",
      "|    std                  | 1.26         |\n",
      "|    value_loss           | 0.101        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.81\n",
      "Episode Finished. Sharpe: 0.81\n",
      "Episode Finished. Sharpe: 0.77\n",
      "Episode Finished. Sharpe: 0.75\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | -1.47       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 599         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09759715  |\n",
      "|    clip_fraction        | 0.502       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -49.4       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.519      |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0618     |\n",
      "|    reward               | 0.52509415  |\n",
      "|    reward_max           | 4.2958617   |\n",
      "|    reward_mean          | 0.005807608 |\n",
      "|    reward_min           | -3.978424   |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 0.0921      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.74\n",
      "Episode Finished. Sharpe: 0.80\n",
      "Episode Finished. Sharpe: 0.82\n",
      "Episode Finished. Sharpe: 0.84\n",
      "Episode Finished. Sharpe: 0.76\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 504            |\n",
      "|    ep_rew_mean          | -1.32          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 599            |\n",
      "|    iterations           | 63             |\n",
      "|    time_elapsed         | 215            |\n",
      "|    total_timesteps      | 129024         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.097186826    |\n",
      "|    clip_fraction        | 0.485          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -49.5          |\n",
      "|    explained_variance   | 0.995          |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | -0.555         |\n",
      "|    n_updates            | 620            |\n",
      "|    policy_gradient_loss | -0.0583        |\n",
      "|    reward               | -0.17587923    |\n",
      "|    reward_max           | 4.3549085      |\n",
      "|    reward_mean          | -0.00065132475 |\n",
      "|    reward_min           | -3.9556313     |\n",
      "|    std                  | 1.27           |\n",
      "|    value_loss           | 0.073          |\n",
      "--------------------------------------------\n",
      "Episode Finished. Sharpe: 0.84\n",
      "Episode Finished. Sharpe: 0.92\n",
      "Episode Finished. Sharpe: 0.82\n",
      "Episode Finished. Sharpe: 0.89\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -1.11        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 599          |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.09358637   |\n",
      "|    clip_fraction        | 0.486        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.6        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.561       |\n",
      "|    n_updates            | 630          |\n",
      "|    policy_gradient_loss | -0.0627      |\n",
      "|    reward               | -0.5290271   |\n",
      "|    reward_max           | 4.2423987    |\n",
      "|    reward_mean          | 0.0065529547 |\n",
      "|    reward_min           | -3.8387613   |\n",
      "|    std                  | 1.27         |\n",
      "|    value_loss           | 0.0841       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.77\n",
      "Episode Finished. Sharpe: 0.71\n",
      "Episode Finished. Sharpe: 1.00\n",
      "Episode Finished. Sharpe: 0.85\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -0.981       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 599          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 222          |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.097875446  |\n",
      "|    clip_fraction        | 0.498        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.7        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.544       |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.065       |\n",
      "|    reward               | -0.16238518  |\n",
      "|    reward_max           | 3.993505     |\n",
      "|    reward_mean          | 0.0051583997 |\n",
      "|    reward_min           | -3.9228103   |\n",
      "|    std                  | 1.27         |\n",
      "|    value_loss           | 0.0825       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.89\n",
      "Episode Finished. Sharpe: 0.85\n",
      "Episode Finished. Sharpe: 0.84\n",
      "Episode Finished. Sharpe: 0.94\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -0.785       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 597          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.091925934  |\n",
      "|    clip_fraction        | 0.481        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -49.9        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.532       |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0631      |\n",
      "|    reward               | 0.6189911    |\n",
      "|    reward_max           | 4.1326733    |\n",
      "|    reward_mean          | 0.0044750185 |\n",
      "|    reward_min           | -4.1139803   |\n",
      "|    std                  | 1.28         |\n",
      "|    value_loss           | 0.106        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.88\n",
      "Episode Finished. Sharpe: 0.82\n",
      "Episode Finished. Sharpe: 0.89\n",
      "Episode Finished. Sharpe: 0.82\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | -0.656      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09141727  |\n",
      "|    clip_fraction        | 0.492       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.563      |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.069      |\n",
      "|    reward               | 0.3044735   |\n",
      "|    reward_max           | 4.352542    |\n",
      "|    reward_mean          | 0.004984879 |\n",
      "|    reward_min           | -4.0644174  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 0.0779      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.76\n",
      "Episode Finished. Sharpe: 0.90\n",
      "Episode Finished. Sharpe: 0.93\n",
      "Episode Finished. Sharpe: 0.87\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -0.387       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 593          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 234          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.09364844   |\n",
      "|    clip_fraction        | 0.479        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50          |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.521       |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.0611      |\n",
      "|    reward               | 0.39950535   |\n",
      "|    reward_max           | 4.311035     |\n",
      "|    reward_mean          | 0.0035110123 |\n",
      "|    reward_min           | -4.247299    |\n",
      "|    std                  | 1.29         |\n",
      "|    value_loss           | 0.0849       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.78\n",
      "Episode Finished. Sharpe: 0.96\n",
      "Episode Finished. Sharpe: 0.81\n",
      "Episode Finished. Sharpe: 0.96\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | -0.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 592          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 238          |\n",
      "|    total_timesteps      | 141312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.13905388   |\n",
      "|    clip_fraction        | 0.504        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.1        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.481       |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.064       |\n",
      "|    reward               | 0.16552493   |\n",
      "|    reward_max           | 4.233389     |\n",
      "|    reward_mean          | 0.0043888083 |\n",
      "|    reward_min           | -3.9853926   |\n",
      "|    std                  | 1.29         |\n",
      "|    value_loss           | 0.0836       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.89\n",
      "Episode Finished. Sharpe: 1.01\n",
      "Episode Finished. Sharpe: 0.98\n",
      "Episode Finished. Sharpe: 0.96\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 0.146       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.096516356 |\n",
      "|    clip_fraction        | 0.487       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.3       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.487      |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0551     |\n",
      "|    reward               | -0.80498815 |\n",
      "|    reward_max           | 4.2313395   |\n",
      "|    reward_mean          | 0.011454714 |\n",
      "|    reward_min           | -4.0181985  |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.78\n",
      "Episode Finished. Sharpe: 0.91\n",
      "Episode Finished. Sharpe: 0.99\n",
      "Episode Finished. Sharpe: 0.83\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | 0.31         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 590          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 246          |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.089140765  |\n",
      "|    clip_fraction        | 0.459        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.4        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.561       |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0669      |\n",
      "|    reward               | -0.04989527  |\n",
      "|    reward_max           | 4.1843214    |\n",
      "|    reward_mean          | 0.0075066774 |\n",
      "|    reward_min           | -4.199698    |\n",
      "|    std                  | 1.3          |\n",
      "|    value_loss           | 0.101        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.84\n",
      "Episode Finished. Sharpe: 0.74\n",
      "Episode Finished. Sharpe: 0.86\n",
      "Episode Finished. Sharpe: 0.75\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | 0.399        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 589          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 250          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.07959305   |\n",
      "|    clip_fraction        | 0.461        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.5        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.539       |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0676      |\n",
      "|    reward               | -1.3404293   |\n",
      "|    reward_max           | 4.225583     |\n",
      "|    reward_mean          | -0.003591645 |\n",
      "|    reward_min           | -3.878902    |\n",
      "|    std                  | 1.31         |\n",
      "|    value_loss           | 0.117        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.97\n",
      "Episode Finished. Sharpe: 0.87\n",
      "Episode Finished. Sharpe: 0.96\n",
      "Episode Finished. Sharpe: 0.77\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 0.562      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 588        |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 254        |\n",
      "|    total_timesteps      | 149504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07495904 |\n",
      "|    clip_fraction        | 0.464      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -50.6      |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.546     |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | -0.074     |\n",
      "|    reward               | 0.10777559 |\n",
      "|    reward_max           | 4.3089743  |\n",
      "|    reward_mean          | 0.00806786 |\n",
      "|    reward_min           | -3.9902263 |\n",
      "|    std                  | 1.31       |\n",
      "|    value_loss           | 0.0974     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 0.90\n",
      "Episode Finished. Sharpe: 0.95\n",
      "Episode Finished. Sharpe: 0.93\n",
      "Episode Finished. Sharpe: 0.91\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | 0.758        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 587          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 257          |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.076202296  |\n",
      "|    clip_fraction        | 0.46         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -50.7        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.512       |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.0713      |\n",
      "|    reward               | 0.5027785    |\n",
      "|    reward_max           | 4.353149     |\n",
      "|    reward_mean          | 0.0046334076 |\n",
      "|    reward_min           | -3.9639888   |\n",
      "|    std                  | 1.31         |\n",
      "|    value_loss           | 0.107        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.90\n",
      "Episode Finished. Sharpe: 0.89\n",
      "Episode Finished. Sharpe: 0.99\n",
      "Episode Finished. Sharpe: 0.82\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 0.893       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11157636  |\n",
      "|    clip_fraction        | 0.485       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.7       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.541      |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0615     |\n",
      "|    reward               | -0.54777944 |\n",
      "|    reward_max           | 4.4059253   |\n",
      "|    reward_mean          | 0.005212591 |\n",
      "|    reward_min           | -3.82817    |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 0.0835      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.95\n",
      "Episode Finished. Sharpe: 0.95\n",
      "Episode Finished. Sharpe: 0.89\n",
      "Episode Finished. Sharpe: 0.99\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 1.12        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 265         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.104195945 |\n",
      "|    clip_fraction        | 0.486       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -50.9       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.558      |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0645     |\n",
      "|    reward               | -2.8907273  |\n",
      "|    reward_max           | 4.225807    |\n",
      "|    reward_mean          | 0.012562115 |\n",
      "|    reward_min           | -3.8889942  |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.99\n",
      "Episode Finished. Sharpe: 0.88\n",
      "Episode Finished. Sharpe: 0.94\n",
      "Episode Finished. Sharpe: 0.93\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | 1.43         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 587          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 268          |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.09225862   |\n",
      "|    clip_fraction        | 0.459        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -51          |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.553       |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.067       |\n",
      "|    reward               | -0.13215974  |\n",
      "|    reward_max           | 4.249183     |\n",
      "|    reward_mean          | 0.0022369146 |\n",
      "|    reward_min           | -3.9659166   |\n",
      "|    std                  | 1.33         |\n",
      "|    value_loss           | 0.101        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 0.91\n",
      "Episode Finished. Sharpe: 0.94\n",
      "Episode Finished. Sharpe: 0.79\n",
      "Episode Finished. Sharpe: 1.03\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 1.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08899067  |\n",
      "|    clip_fraction        | 0.441       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.556      |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0598     |\n",
      "|    reward               | -1.4904139  |\n",
      "|    reward_max           | 4.3541327   |\n",
      "|    reward_mean          | 0.018290302 |\n",
      "|    reward_min           | -3.903148   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.11\n",
      "Episode Finished. Sharpe: 0.92\n",
      "Episode Finished. Sharpe: 0.95\n",
      "Episode Finished. Sharpe: 1.08\n",
      "Episode Finished. Sharpe: 1.14\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 2.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10616029  |\n",
      "|    clip_fraction        | 0.47        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.1       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.53       |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0582     |\n",
      "|    reward               | 0.28329852  |\n",
      "|    reward_max           | 4.3331494   |\n",
      "|    reward_mean          | 0.014985826 |\n",
      "|    reward_min           | -3.908008   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 0.0933      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.20\n",
      "Episode Finished. Sharpe: 0.98\n",
      "Episode Finished. Sharpe: 0.98\n",
      "Episode Finished. Sharpe: 1.05\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 2.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08816187  |\n",
      "|    clip_fraction        | 0.467       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.2       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.59       |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0631     |\n",
      "|    reward               | -0.44968474 |\n",
      "|    reward_max           | 4.5029235   |\n",
      "|    reward_mean          | 0.017759528 |\n",
      "|    reward_min           | -4.156494   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 0.0971      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.98\n",
      "Episode Finished. Sharpe: 0.98\n",
      "Episode Finished. Sharpe: 1.04\n",
      "Episode Finished. Sharpe: 0.97\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 2.79        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0893293   |\n",
      "|    clip_fraction        | 0.467       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.3       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.555      |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.064      |\n",
      "|    reward               | 0.56010693  |\n",
      "|    reward_max           | 4.4134808   |\n",
      "|    reward_mean          | 0.015325556 |\n",
      "|    reward_min           | -3.9851873  |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 0.0919      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.94\n",
      "Episode Finished. Sharpe: 0.89\n",
      "Episode Finished. Sharpe: 0.89\n",
      "Episode Finished. Sharpe: 0.88\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 2.97       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 588        |\n",
      "|    iterations           | 82         |\n",
      "|    time_elapsed         | 285        |\n",
      "|    total_timesteps      | 167936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0959444  |\n",
      "|    clip_fraction        | 0.452      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -51.4      |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.529     |\n",
      "|    n_updates            | 810        |\n",
      "|    policy_gradient_loss | -0.0664    |\n",
      "|    reward               | 0.15446076 |\n",
      "|    reward_max           | 4.5328984  |\n",
      "|    reward_mean          | 0.00829819 |\n",
      "|    reward_min           | -4.058751  |\n",
      "|    std                  | 1.35       |\n",
      "|    value_loss           | 0.083      |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.01\n",
      "Episode Finished. Sharpe: 1.03\n",
      "Episode Finished. Sharpe: 1.10\n",
      "Episode Finished. Sharpe: 1.14\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 3.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09453301  |\n",
      "|    clip_fraction        | 0.432       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.581      |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0586     |\n",
      "|    reward               | -1.8083876  |\n",
      "|    reward_max           | 4.2131214   |\n",
      "|    reward_mean          | 0.016537644 |\n",
      "|    reward_min           | -4.0026474  |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.98\n",
      "Episode Finished. Sharpe: 1.17\n",
      "Episode Finished. Sharpe: 1.02\n",
      "Episode Finished. Sharpe: 1.08\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 3.65        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10138461  |\n",
      "|    clip_fraction        | 0.452       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.6       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.551      |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.067      |\n",
      "|    reward               | -0.24521753 |\n",
      "|    reward_max           | 4.3168473   |\n",
      "|    reward_mean          | 0.018978441 |\n",
      "|    reward_min           | -3.9827843  |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 0.0797      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.92\n",
      "Episode Finished. Sharpe: 1.05\n",
      "Episode Finished. Sharpe: 1.02\n",
      "Episode Finished. Sharpe: 1.01\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 3.92        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.124061756 |\n",
      "|    clip_fraction        | 0.472       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.7       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.504      |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0542     |\n",
      "|    reward               | -0.38649675 |\n",
      "|    reward_max           | 4.1750736   |\n",
      "|    reward_mean          | 0.0127985   |\n",
      "|    reward_min           | -3.941352   |\n",
      "|    std                  | 1.36        |\n",
      "|    value_loss           | 0.0878      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.03\n",
      "Episode Finished. Sharpe: 1.08\n",
      "Episode Finished. Sharpe: 1.05\n",
      "Episode Finished. Sharpe: 0.96\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 4.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.087919824 |\n",
      "|    clip_fraction        | 0.463       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.8       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.563      |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0636     |\n",
      "|    reward               | 1.9049001   |\n",
      "|    reward_max           | 4.340201    |\n",
      "|    reward_mean          | 0.014196687 |\n",
      "|    reward_min           | -4.0845685  |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.15\n",
      "Episode Finished. Sharpe: 0.96\n",
      "Episode Finished. Sharpe: 1.05\n",
      "Episode Finished. Sharpe: 1.05\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 4.63        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10156998  |\n",
      "|    clip_fraction        | 0.457       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.9       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.544      |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0571     |\n",
      "|    reward               | -1.0362874  |\n",
      "|    reward_max           | 4.2626615   |\n",
      "|    reward_mean          | 0.017437696 |\n",
      "|    reward_min           | -3.9841132  |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.97\n",
      "Episode Finished. Sharpe: 1.03\n",
      "Episode Finished. Sharpe: 1.01\n",
      "Episode Finished. Sharpe: 1.06\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 4.9         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09937561  |\n",
      "|    clip_fraction        | 0.474       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -51.9       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.551      |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0628     |\n",
      "|    reward               | -2.2466052  |\n",
      "|    reward_max           | 4.5025935   |\n",
      "|    reward_mean          | 0.010838327 |\n",
      "|    reward_min           | -3.8794844  |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.92\n",
      "Episode Finished. Sharpe: 1.01\n",
      "Episode Finished. Sharpe: 0.92\n",
      "Episode Finished. Sharpe: 1.06\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 5.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09796845  |\n",
      "|    clip_fraction        | 0.454       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52         |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.576      |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0587     |\n",
      "|    reward               | -0.71360487 |\n",
      "|    reward_max           | 4.4147563   |\n",
      "|    reward_mean          | 0.015878553 |\n",
      "|    reward_min           | -3.8339648  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 0.0877      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.07\n",
      "Episode Finished. Sharpe: 1.03\n",
      "Episode Finished. Sharpe: 1.00\n",
      "Episode Finished. Sharpe: 1.11\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 5.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.101467356 |\n",
      "|    clip_fraction        | 0.456       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.1       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.583      |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0594     |\n",
      "|    reward               | 0.6929186   |\n",
      "|    reward_max           | 4.491602    |\n",
      "|    reward_mean          | 0.015047798 |\n",
      "|    reward_min           | -4.087364   |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 0.0886      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.01\n",
      "Episode Finished. Sharpe: 1.09\n",
      "Episode Finished. Sharpe: 1.09\n",
      "Episode Finished. Sharpe: 1.06\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 5.59        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 315         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10222389  |\n",
      "|    clip_fraction        | 0.444       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.579      |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0573     |\n",
      "|    reward               | 0.18966039  |\n",
      "|    reward_max           | 4.509828    |\n",
      "|    reward_mean          | 0.016225157 |\n",
      "|    reward_min           | -3.9275546  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 0.0868      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.09\n",
      "Episode Finished. Sharpe: 1.05\n",
      "Episode Finished. Sharpe: 1.02\n",
      "Episode Finished. Sharpe: 1.13\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 5.92        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11108917  |\n",
      "|    clip_fraction        | 0.467       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.2       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.596      |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0615     |\n",
      "|    reward               | 0.5226041   |\n",
      "|    reward_max           | 4.580241    |\n",
      "|    reward_mean          | 0.016487764 |\n",
      "|    reward_min           | -3.9039044  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 0.0782      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.98\n",
      "Episode Finished. Sharpe: 1.28\n",
      "Episode Finished. Sharpe: 1.10\n",
      "Episode Finished. Sharpe: 1.13\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 6.27        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08240941  |\n",
      "|    clip_fraction        | 0.454       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.58       |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0611     |\n",
      "|    reward               | 1.2070448   |\n",
      "|    reward_max           | 4.5466595   |\n",
      "|    reward_mean          | 0.022113448 |\n",
      "|    reward_min           | -3.9391613  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 0.074       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.10\n",
      "Episode Finished. Sharpe: 1.08\n",
      "Episode Finished. Sharpe: 1.01\n",
      "Episode Finished. Sharpe: 1.11\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 6.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10734524  |\n",
      "|    clip_fraction        | 0.472       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.3       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.581      |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0596     |\n",
      "|    reward               | 0.5870732   |\n",
      "|    reward_max           | 4.5077076   |\n",
      "|    reward_mean          | 0.021226952 |\n",
      "|    reward_min           | -3.9762597  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 0.0979      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.01\n",
      "Episode Finished. Sharpe: 1.07\n",
      "Episode Finished. Sharpe: 1.06\n",
      "Episode Finished. Sharpe: 1.02\n",
      "Episode Finished. Sharpe: 1.03\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 6.71        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.15261827  |\n",
      "|    clip_fraction        | 0.462       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.4       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.575      |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0536     |\n",
      "|    reward               | 0.033629324 |\n",
      "|    reward_max           | 4.4285226   |\n",
      "|    reward_mean          | 0.017005127 |\n",
      "|    reward_min           | -3.9371011  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 0.0815      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.06\n",
      "Episode Finished. Sharpe: 1.19\n",
      "Episode Finished. Sharpe: 1.17\n",
      "Episode Finished. Sharpe: 1.06\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 7.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 332         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.132662    |\n",
      "|    clip_fraction        | 0.464       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.536      |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.055      |\n",
      "|    reward               | 0.6195915   |\n",
      "|    reward_max           | 4.646907    |\n",
      "|    reward_mean          | 0.024620334 |\n",
      "|    reward_min           | -3.9735389  |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 0.0913      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.02\n",
      "Episode Finished. Sharpe: 1.11\n",
      "Episode Finished. Sharpe: 1.05\n",
      "Episode Finished. Sharpe: 1.19\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 7.39        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 336         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11778387  |\n",
      "|    clip_fraction        | 0.471       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.6       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.579      |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0619     |\n",
      "|    reward               | -0.32677644 |\n",
      "|    reward_max           | 4.3397903   |\n",
      "|    reward_mean          | 0.019898428 |\n",
      "|    reward_min           | -3.9508781  |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.27\n",
      "Episode Finished. Sharpe: 1.16\n",
      "Episode Finished. Sharpe: 1.15\n",
      "Episode Finished. Sharpe: 1.17\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 7.79        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09499644  |\n",
      "|    clip_fraction        | 0.473       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.7       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.597      |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0643     |\n",
      "|    reward               | -0.17834772 |\n",
      "|    reward_max           | 4.45196     |\n",
      "|    reward_mean          | 0.027031647 |\n",
      "|    reward_min           | -3.8490725  |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 0.0867      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.05\n",
      "Episode Finished. Sharpe: 1.09\n",
      "Episode Finished. Sharpe: 1.04\n",
      "Episode Finished. Sharpe: 1.31\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 8.08       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 591        |\n",
      "|    iterations           | 99         |\n",
      "|    time_elapsed         | 342        |\n",
      "|    total_timesteps      | 202752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09065468 |\n",
      "|    clip_fraction        | 0.448      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -52.8      |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.539     |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | -0.0636    |\n",
      "|    reward               | 0.30348337 |\n",
      "|    reward_max           | 4.452118   |\n",
      "|    reward_mean          | 0.02297234 |\n",
      "|    reward_min           | -4.042038  |\n",
      "|    std                  | 1.41       |\n",
      "|    value_loss           | 0.107      |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.00\n",
      "Episode Finished. Sharpe: 1.15\n",
      "Episode Finished. Sharpe: 1.15\n",
      "Episode Finished. Sharpe: 1.13\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 8.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 346         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10785259  |\n",
      "|    clip_fraction        | 0.468       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -52.9       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.525      |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0644     |\n",
      "|    reward               | -0.88149667 |\n",
      "|    reward_max           | 4.372707    |\n",
      "|    reward_mean          | 0.019376395 |\n",
      "|    reward_min           | -4.074155   |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.11\n",
      "Episode Finished. Sharpe: 1.19\n",
      "Episode Finished. Sharpe: 0.99\n",
      "Episode Finished. Sharpe: 0.98\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 8.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.07925603  |\n",
      "|    clip_fraction        | 0.455       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53         |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.572      |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.0592     |\n",
      "|    reward               | 0.8170776   |\n",
      "|    reward_max           | 4.454911    |\n",
      "|    reward_mean          | 0.017851872 |\n",
      "|    reward_min           | -4.080569   |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 0.0918      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.09\n",
      "Episode Finished. Sharpe: 1.00\n",
      "Episode Finished. Sharpe: 1.08\n",
      "Episode Finished. Sharpe: 1.08\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 8.68        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.091446035 |\n",
      "|    clip_fraction        | 0.442       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.593      |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.0567     |\n",
      "|    reward               | -0.20442367 |\n",
      "|    reward_max           | 4.6293716   |\n",
      "|    reward_mean          | 0.018027198 |\n",
      "|    reward_min           | -3.9101062  |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 0.0847      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.16\n",
      "Episode Finished. Sharpe: 1.09\n",
      "Episode Finished. Sharpe: 1.10\n",
      "Episode Finished. Sharpe: 1.07\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 8.89        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 356         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08906403  |\n",
      "|    clip_fraction        | 0.437       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.1       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.584      |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0565     |\n",
      "|    reward               | 1.1598157   |\n",
      "|    reward_max           | 4.416942    |\n",
      "|    reward_mean          | 0.021080533 |\n",
      "|    reward_min           | -4.068173   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 0.0849      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.11\n",
      "Episode Finished. Sharpe: 1.10\n",
      "Episode Finished. Sharpe: 1.16\n",
      "Episode Finished. Sharpe: 1.00\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 8.88       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 592        |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 359        |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08746798 |\n",
      "|    clip_fraction        | 0.464      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -53.3      |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.571     |\n",
      "|    n_updates            | 1030       |\n",
      "|    policy_gradient_loss | -0.0692    |\n",
      "|    reward               | 1.1039522  |\n",
      "|    reward_max           | 4.2971864  |\n",
      "|    reward_mean          | 0.0189839  |\n",
      "|    reward_min           | -4.0702024 |\n",
      "|    std                  | 1.44       |\n",
      "|    value_loss           | 0.0935     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.14\n",
      "Episode Finished. Sharpe: 1.22\n",
      "Episode Finished. Sharpe: 1.09\n",
      "Episode Finished. Sharpe: 1.12\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 9.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08956678  |\n",
      "|    clip_fraction        | 0.443       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.4       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.597      |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0617     |\n",
      "|    reward               | 0.41354367  |\n",
      "|    reward_max           | 4.315037    |\n",
      "|    reward_mean          | 0.022225792 |\n",
      "|    reward_min           | -3.9792807  |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 0.0935      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.10\n",
      "Episode Finished. Sharpe: 1.13\n",
      "Episode Finished. Sharpe: 1.13\n",
      "Episode Finished. Sharpe: 0.99\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 9.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 366         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09424908  |\n",
      "|    clip_fraction        | 0.45        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.4       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.603      |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0616     |\n",
      "|    reward               | -0.08298174 |\n",
      "|    reward_max           | 4.4007683   |\n",
      "|    reward_mean          | 0.015546822 |\n",
      "|    reward_min           | -3.918726   |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 0.0867      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.20\n",
      "Episode Finished. Sharpe: 1.14\n",
      "Episode Finished. Sharpe: 1.22\n",
      "Episode Finished. Sharpe: 1.16\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 9.58        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09406852  |\n",
      "|    clip_fraction        | 0.456       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.5       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.575      |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.069      |\n",
      "|    reward               | -0.561447   |\n",
      "|    reward_max           | 4.553783    |\n",
      "|    reward_mean          | 0.028269727 |\n",
      "|    reward_min           | -3.919965   |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.23\n",
      "Episode Finished. Sharpe: 1.10\n",
      "Episode Finished. Sharpe: 1.13\n",
      "Episode Finished. Sharpe: 1.09\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 9.68        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 373         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10481386  |\n",
      "|    clip_fraction        | 0.44        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.6       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.594      |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.0689     |\n",
      "|    reward               | -1.2196256  |\n",
      "|    reward_max           | 4.4623537   |\n",
      "|    reward_mean          | 0.019141654 |\n",
      "|    reward_min           | -4.107884   |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 0.0718      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.17\n",
      "Episode Finished. Sharpe: 1.15\n",
      "Episode Finished. Sharpe: 1.15\n",
      "Episode Finished. Sharpe: 1.33\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 9.89        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10204793  |\n",
      "|    clip_fraction        | 0.458       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.627      |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0654     |\n",
      "|    reward               | -0.41122955 |\n",
      "|    reward_max           | 4.4566026   |\n",
      "|    reward_mean          | 0.026792921 |\n",
      "|    reward_min           | -4.1189055  |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 0.0714      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.16\n",
      "Episode Finished. Sharpe: 1.04\n",
      "Episode Finished. Sharpe: 1.13\n",
      "Episode Finished. Sharpe: 1.08\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 9.99        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.092494905 |\n",
      "|    clip_fraction        | 0.426       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.589      |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.0533     |\n",
      "|    reward               | 0.17093588  |\n",
      "|    reward_max           | 4.4125195   |\n",
      "|    reward_mean          | 0.022816235 |\n",
      "|    reward_min           | -4.063956   |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 0.0879      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.17\n",
      "Episode Finished. Sharpe: 1.19\n",
      "Episode Finished. Sharpe: 1.21\n",
      "Episode Finished. Sharpe: 1.29\n",
      "Episode Finished. Sharpe: 1.25\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 10.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0833949   |\n",
      "|    clip_fraction        | 0.438       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -53.9       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.559      |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0627     |\n",
      "|    reward               | 0.3258474   |\n",
      "|    reward_max           | 4.350471    |\n",
      "|    reward_mean          | 0.030358523 |\n",
      "|    reward_min           | -4.132673   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 0.0958      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.12\n",
      "Episode Finished. Sharpe: 1.25\n",
      "Episode Finished. Sharpe: 1.35\n",
      "Episode Finished. Sharpe: 1.18\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 10.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 386         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10473277  |\n",
      "|    clip_fraction        | 0.431       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.584      |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.0573     |\n",
      "|    reward               | 0.15420336  |\n",
      "|    reward_max           | 4.6732774   |\n",
      "|    reward_mean          | 0.029636605 |\n",
      "|    reward_min           | -4.0513716  |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 0.0866      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.17\n",
      "Episode Finished. Sharpe: 1.11\n",
      "Episode Finished. Sharpe: 1.27\n",
      "Episode Finished. Sharpe: 1.12\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 10.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.098322704 |\n",
      "|    clip_fraction        | 0.452       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.589      |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0656     |\n",
      "|    reward               | -0.03586638 |\n",
      "|    reward_max           | 4.4270587   |\n",
      "|    reward_mean          | 0.027971704 |\n",
      "|    reward_min           | -3.8066144  |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.26\n",
      "Episode Finished. Sharpe: 1.20\n",
      "Episode Finished. Sharpe: 1.14\n",
      "Episode Finished. Sharpe: 1.28\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 11.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 593        |\n",
      "|    iterations           | 114        |\n",
      "|    time_elapsed         | 393        |\n",
      "|    total_timesteps      | 233472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0963035  |\n",
      "|    clip_fraction        | 0.456      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.2      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.617     |\n",
      "|    n_updates            | 1130       |\n",
      "|    policy_gradient_loss | -0.056     |\n",
      "|    reward               | 0.8288277  |\n",
      "|    reward_max           | 4.397067   |\n",
      "|    reward_mean          | 0.02744079 |\n",
      "|    reward_min           | -3.8670824 |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 0.0759     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.23\n",
      "Episode Finished. Sharpe: 1.13\n",
      "Episode Finished. Sharpe: 1.19\n",
      "Episode Finished. Sharpe: 1.10\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 11.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 593        |\n",
      "|    iterations           | 115        |\n",
      "|    time_elapsed         | 396        |\n",
      "|    total_timesteps      | 235520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.1259624  |\n",
      "|    clip_fraction        | 0.451      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.3      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.612     |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | -0.0601    |\n",
      "|    reward               | 0.59696454 |\n",
      "|    reward_max           | 4.3199434  |\n",
      "|    reward_mean          | 0.02570842 |\n",
      "|    reward_min           | -3.8377638 |\n",
      "|    std                  | 1.48       |\n",
      "|    value_loss           | 0.0944     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.13\n",
      "Episode Finished. Sharpe: 1.21\n",
      "Episode Finished. Sharpe: 1.17\n",
      "Episode Finished. Sharpe: 1.15\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 11.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 400         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11219951  |\n",
      "|    clip_fraction        | 0.462       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.592      |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.0581     |\n",
      "|    reward               | 0.0320911   |\n",
      "|    reward_max           | 4.4661236   |\n",
      "|    reward_mean          | 0.021281742 |\n",
      "|    reward_min           | -3.7857664  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 0.0711      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.18\n",
      "Episode Finished. Sharpe: 1.15\n",
      "Episode Finished. Sharpe: 1.25\n",
      "Episode Finished. Sharpe: 1.27\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 11.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.115694    |\n",
      "|    clip_fraction        | 0.465       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.574      |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0575     |\n",
      "|    reward               | -0.20651774 |\n",
      "|    reward_max           | 4.6466174   |\n",
      "|    reward_mean          | 0.030783517 |\n",
      "|    reward_min           | -3.9741297  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 0.0816      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.30\n",
      "Episode Finished. Sharpe: 1.21\n",
      "Episode Finished. Sharpe: 1.22\n",
      "Episode Finished. Sharpe: 1.12\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 11.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 406         |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09042235  |\n",
      "|    clip_fraction        | 0.436       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.601      |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.0635     |\n",
      "|    reward               | 0.91806144  |\n",
      "|    reward_max           | 4.4730015   |\n",
      "|    reward_mean          | 0.025873788 |\n",
      "|    reward_min           | -4.038588   |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 0.0858      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.29\n",
      "Episode Finished. Sharpe: 1.15\n",
      "Episode Finished. Sharpe: 1.24\n",
      "Episode Finished. Sharpe: 1.24\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 11.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 410         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.099692985 |\n",
      "|    clip_fraction        | 0.474       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.59       |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0469     |\n",
      "|    reward               | -1.1014513  |\n",
      "|    reward_max           | 4.5091057   |\n",
      "|    reward_mean          | 0.027813453 |\n",
      "|    reward_min           | -4.029031   |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 0.0748      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.20\n",
      "Episode Finished. Sharpe: 1.30\n",
      "Episode Finished. Sharpe: 1.16\n",
      "Episode Finished. Sharpe: 1.21\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 12          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 413         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10253799  |\n",
      "|    clip_fraction        | 0.453       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.595      |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0552     |\n",
      "|    reward               | 0.92820334  |\n",
      "|    reward_max           | 4.4656367   |\n",
      "|    reward_mean          | 0.027876226 |\n",
      "|    reward_min           | -4.01479    |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.11\n",
      "Episode Finished. Sharpe: 1.17\n",
      "Episode Finished. Sharpe: 1.21\n",
      "Episode Finished. Sharpe: 1.22\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 12.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 416         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.13751905  |\n",
      "|    clip_fraction        | 0.48        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.552      |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.0578     |\n",
      "|    reward               | 1.2969409   |\n",
      "|    reward_max           | 4.2534175   |\n",
      "|    reward_mean          | 0.023275794 |\n",
      "|    reward_min           | -4.0121107  |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 0.0745      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.32\n",
      "Episode Finished. Sharpe: 1.24\n",
      "Episode Finished. Sharpe: 1.25\n",
      "Episode Finished. Sharpe: 1.22\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 12.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 594        |\n",
      "|    iterations           | 122        |\n",
      "|    time_elapsed         | 420        |\n",
      "|    total_timesteps      | 249856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.105708   |\n",
      "|    clip_fraction        | 0.444      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.9      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.612     |\n",
      "|    n_updates            | 1210       |\n",
      "|    policy_gradient_loss | -0.0591    |\n",
      "|    reward               | -0.6707665 |\n",
      "|    reward_max           | 4.3854966  |\n",
      "|    reward_mean          | 0.02649734 |\n",
      "|    reward_min           | -3.8131154 |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 0.0797     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.15\n",
      "Episode Finished. Sharpe: 1.31\n",
      "Episode Finished. Sharpe: 1.18\n",
      "Episode Finished. Sharpe: 1.23\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 12.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 594        |\n",
      "|    iterations           | 123        |\n",
      "|    time_elapsed         | 423        |\n",
      "|    total_timesteps      | 251904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07864386 |\n",
      "|    clip_fraction        | 0.436      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.9      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.599     |\n",
      "|    n_updates            | 1220       |\n",
      "|    policy_gradient_loss | -0.0638    |\n",
      "|    reward               | 0.6701581  |\n",
      "|    reward_max           | 4.4986386  |\n",
      "|    reward_mean          | 0.03602889 |\n",
      "|    reward_min           | -3.9780242 |\n",
      "|    std                  | 1.52       |\n",
      "|    value_loss           | 0.0798     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.42\n",
      "Episode Finished. Sharpe: 1.30\n",
      "Episode Finished. Sharpe: 1.23\n",
      "Episode Finished. Sharpe: 1.33\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 12.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 426         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0874024   |\n",
      "|    clip_fraction        | 0.425       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55         |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.612      |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.063      |\n",
      "|    reward               | -2.044804   |\n",
      "|    reward_max           | 4.6842227   |\n",
      "|    reward_mean          | 0.023321548 |\n",
      "|    reward_min           | -3.8750162  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 0.0881      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.23\n",
      "Episode Finished. Sharpe: 1.18\n",
      "Episode Finished. Sharpe: 1.39\n",
      "Episode Finished. Sharpe: 1.29\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 12.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 430         |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08576408  |\n",
      "|    clip_fraction        | 0.436       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.1       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.6        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.0609     |\n",
      "|    reward               | 0.39830264  |\n",
      "|    reward_max           | 4.373995    |\n",
      "|    reward_mean          | 0.040415145 |\n",
      "|    reward_min           | -3.8997424  |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.27\n",
      "Episode Finished. Sharpe: 1.19\n",
      "Episode Finished. Sharpe: 1.30\n",
      "Episode Finished. Sharpe: 1.22\n",
      "Episode Finished. Sharpe: 1.15\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 13.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10380359  |\n",
      "|    clip_fraction        | 0.446       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.2       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.588      |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.0608     |\n",
      "|    reward               | -0.18434781 |\n",
      "|    reward_max           | 4.2120447   |\n",
      "|    reward_mean          | 0.02705763  |\n",
      "|    reward_min           | -3.9061651  |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 0.0802      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.29\n",
      "Episode Finished. Sharpe: 1.30\n",
      "Episode Finished. Sharpe: 1.20\n",
      "Episode Finished. Sharpe: 1.30\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 13.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 436         |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.15196997  |\n",
      "|    clip_fraction        | 0.446       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.3       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.615      |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.0464     |\n",
      "|    reward               | -0.21837242 |\n",
      "|    reward_max           | 4.4608917   |\n",
      "|    reward_mean          | 0.03283651  |\n",
      "|    reward_min           | -3.856789   |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 0.0859      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.22\n",
      "Episode Finished. Sharpe: 1.28\n",
      "Episode Finished. Sharpe: 1.28\n",
      "Episode Finished. Sharpe: 1.20\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 13.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.089923404 |\n",
      "|    clip_fraction        | 0.432       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.4       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.618      |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.0578     |\n",
      "|    reward               | -0.20513916 |\n",
      "|    reward_max           | 4.6430626   |\n",
      "|    reward_mean          | 0.032332025 |\n",
      "|    reward_min           | -3.9621367  |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 0.0786      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.23\n",
      "Episode Finished. Sharpe: 1.34\n",
      "Episode Finished. Sharpe: 1.30\n",
      "Episode Finished. Sharpe: 1.34\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 13.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09806396  |\n",
      "|    clip_fraction        | 0.44        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.4       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.611      |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0614     |\n",
      "|    reward               | 0.5892684   |\n",
      "|    reward_max           | 4.7098393   |\n",
      "|    reward_mean          | 0.034403812 |\n",
      "|    reward_min           | -3.929013   |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 0.0737      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.22\n",
      "Episode Finished. Sharpe: 1.20\n",
      "Episode Finished. Sharpe: 1.17\n",
      "Episode Finished. Sharpe: 1.25\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 13.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 446         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.07820861  |\n",
      "|    clip_fraction        | 0.427       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.5       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.627      |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.0612     |\n",
      "|    reward               | 0.30142802  |\n",
      "|    reward_max           | 4.5531034   |\n",
      "|    reward_mean          | 0.028483342 |\n",
      "|    reward_min           | -3.9395535  |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 0.0602      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.35\n",
      "Episode Finished. Sharpe: 1.33\n",
      "Episode Finished. Sharpe: 1.38\n",
      "Episode Finished. Sharpe: 1.24\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 14.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.093639165 |\n",
      "|    clip_fraction        | 0.433       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.6       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.626      |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0615     |\n",
      "|    reward               | 0.5445712   |\n",
      "|    reward_max           | 4.7906766   |\n",
      "|    reward_mean          | 0.03487423  |\n",
      "|    reward_min           | -3.8654535  |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 0.0712      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.21\n",
      "Episode Finished. Sharpe: 1.20\n",
      "Episode Finished. Sharpe: 1.32\n",
      "Episode Finished. Sharpe: 1.38\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 14.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 453         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09325989  |\n",
      "|    clip_fraction        | 0.432       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.7       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.612      |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.0577     |\n",
      "|    reward               | 0.105404876 |\n",
      "|    reward_max           | 4.6235557   |\n",
      "|    reward_mean          | 0.032071535 |\n",
      "|    reward_min           | -3.8346014  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 0.0861      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.41\n",
      "Episode Finished. Sharpe: 1.34\n",
      "Episode Finished. Sharpe: 1.34\n",
      "Episode Finished. Sharpe: 1.27\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 14.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 595        |\n",
      "|    iterations           | 133        |\n",
      "|    time_elapsed         | 457        |\n",
      "|    total_timesteps      | 272384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11715725 |\n",
      "|    clip_fraction        | 0.46       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.8      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.61      |\n",
      "|    n_updates            | 1320       |\n",
      "|    policy_gradient_loss | -0.0554    |\n",
      "|    reward               | -0.5937772 |\n",
      "|    reward_max           | 4.636448   |\n",
      "|    reward_mean          | 0.03780206 |\n",
      "|    reward_min           | -3.8248184 |\n",
      "|    std                  | 1.56       |\n",
      "|    value_loss           | 0.0797     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.36\n",
      "Episode Finished. Sharpe: 1.23\n",
      "Episode Finished. Sharpe: 1.14\n",
      "Episode Finished. Sharpe: 1.30\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 14.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 460         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08750081  |\n",
      "|    clip_fraction        | 0.416       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.623      |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.062      |\n",
      "|    reward               | -0.23418516 |\n",
      "|    reward_max           | 4.4485693   |\n",
      "|    reward_mean          | 0.032362163 |\n",
      "|    reward_min           | -3.8542829  |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 0.0799      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.28\n",
      "Episode Finished. Sharpe: 1.32\n",
      "Episode Finished. Sharpe: 1.26\n",
      "Episode Finished. Sharpe: 1.15\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 14.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 463         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11612922  |\n",
      "|    clip_fraction        | 0.427       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.605      |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.0602     |\n",
      "|    reward               | -1.1462748  |\n",
      "|    reward_max           | 4.357582    |\n",
      "|    reward_mean          | 0.027669191 |\n",
      "|    reward_min           | -3.7616458  |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 0.0814      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.31\n",
      "Episode Finished. Sharpe: 1.28\n",
      "Episode Finished. Sharpe: 1.42\n",
      "Episode Finished. Sharpe: 1.43\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 15.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 596        |\n",
      "|    iterations           | 136        |\n",
      "|    time_elapsed         | 466        |\n",
      "|    total_timesteps      | 278528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09557414 |\n",
      "|    clip_fraction        | 0.44       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56        |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.582     |\n",
      "|    n_updates            | 1350       |\n",
      "|    policy_gradient_loss | -0.0598    |\n",
      "|    reward               | 0.24550079 |\n",
      "|    reward_max           | 4.566332   |\n",
      "|    reward_mean          | 0.03962601 |\n",
      "|    reward_min           | -4.0347443 |\n",
      "|    std                  | 1.58       |\n",
      "|    value_loss           | 0.0904     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.25\n",
      "Episode Finished. Sharpe: 1.36\n",
      "Episode Finished. Sharpe: 1.33\n",
      "Episode Finished. Sharpe: 1.29\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 15.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 596        |\n",
      "|    iterations           | 137        |\n",
      "|    time_elapsed         | 470        |\n",
      "|    total_timesteps      | 280576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0986603  |\n",
      "|    clip_fraction        | 0.422      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.1      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.611     |\n",
      "|    n_updates            | 1360       |\n",
      "|    policy_gradient_loss | -0.058     |\n",
      "|    reward               | 0.44204614 |\n",
      "|    reward_max           | 4.497914   |\n",
      "|    reward_mean          | 0.03016948 |\n",
      "|    reward_min           | -3.9950826 |\n",
      "|    std                  | 1.58       |\n",
      "|    value_loss           | 0.0803     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.30\n",
      "Episode Finished. Sharpe: 1.34\n",
      "Episode Finished. Sharpe: 1.31\n",
      "Episode Finished. Sharpe: 1.32\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 15.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 473         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11311861  |\n",
      "|    clip_fraction        | 0.449       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.607      |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.0595     |\n",
      "|    reward               | -0.43821234 |\n",
      "|    reward_max           | 4.5452905   |\n",
      "|    reward_mean          | 0.03406141  |\n",
      "|    reward_min           | -4.017592   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 0.0801      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.39\n",
      "Episode Finished. Sharpe: 1.21\n",
      "Episode Finished. Sharpe: 1.24\n",
      "Episode Finished. Sharpe: 1.25\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 15.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 477         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11541459  |\n",
      "|    clip_fraction        | 0.453       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.666      |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0639     |\n",
      "|    reward               | -2.7848487  |\n",
      "|    reward_max           | 4.315198    |\n",
      "|    reward_mean          | 0.032095086 |\n",
      "|    reward_min           | -3.8852005  |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 0.0647      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.28\n",
      "Episode Finished. Sharpe: 1.36\n",
      "Episode Finished. Sharpe: 1.38\n",
      "Episode Finished. Sharpe: 1.34\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 15.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 480         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09485533  |\n",
      "|    clip_fraction        | 0.455       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.613      |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.0657     |\n",
      "|    reward               | -0.0734071  |\n",
      "|    reward_max           | 4.4956813   |\n",
      "|    reward_mean          | 0.031796377 |\n",
      "|    reward_min           | -3.99476    |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 0.0943      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.37\n",
      "Episode Finished. Sharpe: 1.30\n",
      "Episode Finished. Sharpe: 1.39\n",
      "Episode Finished. Sharpe: 1.36\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 16.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 596        |\n",
      "|    iterations           | 141        |\n",
      "|    time_elapsed         | 484        |\n",
      "|    total_timesteps      | 288768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07785116 |\n",
      "|    clip_fraction        | 0.416      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.4      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.651     |\n",
      "|    n_updates            | 1400       |\n",
      "|    policy_gradient_loss | -0.0673    |\n",
      "|    reward               | -1.3784131 |\n",
      "|    reward_max           | 4.307082   |\n",
      "|    reward_mean          | 0.04338908 |\n",
      "|    reward_min           | -3.8351998 |\n",
      "|    std                  | 1.6        |\n",
      "|    value_loss           | 0.0685     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.32\n",
      "Episode Finished. Sharpe: 1.42\n",
      "Episode Finished. Sharpe: 1.28\n",
      "Episode Finished. Sharpe: 1.31\n",
      "Episode Finished. Sharpe: 1.39\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 16.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 595        |\n",
      "|    iterations           | 142        |\n",
      "|    time_elapsed         | 488        |\n",
      "|    total_timesteps      | 290816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08865538 |\n",
      "|    clip_fraction        | 0.414      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.5      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.592     |\n",
      "|    n_updates            | 1410       |\n",
      "|    policy_gradient_loss | -0.0639    |\n",
      "|    reward               | 0.17824459 |\n",
      "|    reward_max           | 4.3758087  |\n",
      "|    reward_mean          | 0.03663398 |\n",
      "|    reward_min           | -3.9407558 |\n",
      "|    std                  | 1.6        |\n",
      "|    value_loss           | 0.0785     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.20\n",
      "Episode Finished. Sharpe: 1.39\n",
      "Episode Finished. Sharpe: 1.39\n",
      "Episode Finished. Sharpe: 1.42\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 16.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 491         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11442323  |\n",
      "|    clip_fraction        | 0.438       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.609      |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.0659     |\n",
      "|    reward               | -0.3728561  |\n",
      "|    reward_max           | 4.15994     |\n",
      "|    reward_mean          | 0.037600778 |\n",
      "|    reward_min           | -3.8286679  |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 0.0852      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.45\n",
      "Episode Finished. Sharpe: 1.43\n",
      "Episode Finished. Sharpe: 1.30\n",
      "Episode Finished. Sharpe: 1.34\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 16.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 495         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.088299505 |\n",
      "|    clip_fraction        | 0.448       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.625      |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.0535     |\n",
      "|    reward               | 0.5194192   |\n",
      "|    reward_max           | 4.6372046   |\n",
      "|    reward_mean          | 0.04203279  |\n",
      "|    reward_min           | -3.895015   |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.43\n",
      "Episode Finished. Sharpe: 1.38\n",
      "Episode Finished. Sharpe: 1.51\n",
      "Episode Finished. Sharpe: 1.34\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 16.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 499         |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.1072848   |\n",
      "|    clip_fraction        | 0.427       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.627      |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.0629     |\n",
      "|    reward               | 0.13325176  |\n",
      "|    reward_max           | 4.444462    |\n",
      "|    reward_mean          | 0.040249065 |\n",
      "|    reward_min           | -3.7689805  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 0.08        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.42\n",
      "Episode Finished. Sharpe: 1.48\n",
      "Episode Finished. Sharpe: 1.46\n",
      "Episode Finished. Sharpe: 1.43\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 17.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.18371576  |\n",
      "|    clip_fraction        | 0.458       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.629      |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.0642     |\n",
      "|    reward               | -1.746542   |\n",
      "|    reward_max           | 4.7170324   |\n",
      "|    reward_mean          | 0.041817654 |\n",
      "|    reward_min           | -3.9451573  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 0.0641      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.42\n",
      "Episode Finished. Sharpe: 1.42\n",
      "Episode Finished. Sharpe: 1.45\n",
      "Episode Finished. Sharpe: 1.46\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 17.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 507         |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.1297522   |\n",
      "|    clip_fraction        | 0.445       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.624      |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.0499     |\n",
      "|    reward               | -0.17999479 |\n",
      "|    reward_max           | 4.5790896   |\n",
      "|    reward_mean          | 0.045341875 |\n",
      "|    reward_min           | -3.9574034  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 0.0742      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.49\n",
      "Episode Finished. Sharpe: 1.43\n",
      "Episode Finished. Sharpe: 1.42\n",
      "Episode Finished. Sharpe: 1.54\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 17.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 511         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10753326  |\n",
      "|    clip_fraction        | 0.458       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.595      |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    reward               | -0.3203276  |\n",
      "|    reward_max           | 4.7222624   |\n",
      "|    reward_mean          | 0.043623388 |\n",
      "|    reward_min           | -3.81063    |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 0.0704      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.40\n",
      "Episode Finished. Sharpe: 1.39\n",
      "Episode Finished. Sharpe: 1.35\n",
      "Episode Finished. Sharpe: 1.53\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 18          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 514         |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10948497  |\n",
      "|    clip_fraction        | 0.446       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.618      |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.056      |\n",
      "|    reward               | 1.6868136   |\n",
      "|    reward_max           | 4.2945976   |\n",
      "|    reward_mean          | 0.040410798 |\n",
      "|    reward_min           | -3.712216   |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 0.0708      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.28\n",
      "Episode Finished. Sharpe: 1.43\n",
      "Episode Finished. Sharpe: 1.45\n",
      "Episode Finished. Sharpe: 1.41\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 18.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 518         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.1144865   |\n",
      "|    clip_fraction        | 0.447       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.633      |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0603     |\n",
      "|    reward               | -0.92343843 |\n",
      "|    reward_max           | 4.4535975   |\n",
      "|    reward_mean          | 0.041775364 |\n",
      "|    reward_min           | -3.6944065  |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 0.0734      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.54\n",
      "Episode Finished. Sharpe: 1.42\n",
      "Episode Finished. Sharpe: 1.39\n",
      "Episode Finished. Sharpe: 1.47\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 18.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.12275754  |\n",
      "|    clip_fraction        | 0.437       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.607      |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.0525     |\n",
      "|    reward               | -1.7209008  |\n",
      "|    reward_max           | 4.5877833   |\n",
      "|    reward_mean          | 0.040198095 |\n",
      "|    reward_min           | -3.7325113  |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 0.0785      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.45\n",
      "Episode Finished. Sharpe: 1.47\n",
      "Episode Finished. Sharpe: 1.55\n",
      "Episode Finished. Sharpe: 1.33\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 18.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 525         |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11554923  |\n",
      "|    clip_fraction        | 0.446       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.2       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.631      |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.0573     |\n",
      "|    reward               | -0.66088635 |\n",
      "|    reward_max           | 4.4182262   |\n",
      "|    reward_mean          | 0.045378756 |\n",
      "|    reward_min           | -3.812247   |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 0.0794      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.45\n",
      "Episode Finished. Sharpe: 1.36\n",
      "Episode Finished. Sharpe: 1.43\n",
      "Episode Finished. Sharpe: 1.55\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 18.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 529         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.101146415 |\n",
      "|    clip_fraction        | 0.448       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.58       |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.0602     |\n",
      "|    reward               | 0.6519372   |\n",
      "|    reward_max           | 4.538512    |\n",
      "|    reward_mean          | 0.03942484  |\n",
      "|    reward_min           | -3.6880736  |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 0.0807      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.33\n",
      "Episode Finished. Sharpe: 1.30\n",
      "Episode Finished. Sharpe: 1.41\n",
      "Episode Finished. Sharpe: 1.30\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 19          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 533         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10464509  |\n",
      "|    clip_fraction        | 0.429       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.4       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.649      |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.0595     |\n",
      "|    reward               | 0.29918563  |\n",
      "|    reward_max           | 4.4045305   |\n",
      "|    reward_mean          | 0.036087193 |\n",
      "|    reward_min           | -3.7771118  |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 0.0775      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.48\n",
      "Episode Finished. Sharpe: 1.44\n",
      "Episode Finished. Sharpe: 1.33\n",
      "Episode Finished. Sharpe: 1.34\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 19.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 590        |\n",
      "|    iterations           | 155        |\n",
      "|    time_elapsed         | 537        |\n",
      "|    total_timesteps      | 317440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11099423 |\n",
      "|    clip_fraction        | 0.445      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.6      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.611     |\n",
      "|    n_updates            | 1540       |\n",
      "|    policy_gradient_loss | -0.0368    |\n",
      "|    reward               | 0.5613587  |\n",
      "|    reward_max           | 4.5410395  |\n",
      "|    reward_mean          | 0.03886717 |\n",
      "|    reward_min           | -3.7781346 |\n",
      "|    std                  | 1.66       |\n",
      "|    value_loss           | 0.0729     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.42\n",
      "Episode Finished. Sharpe: 1.36\n",
      "Episode Finished. Sharpe: 1.43\n",
      "Episode Finished. Sharpe: 1.50\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 19.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 541         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09643551  |\n",
      "|    clip_fraction        | 0.435       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.611      |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.0582     |\n",
      "|    reward               | 1.2035891   |\n",
      "|    reward_max           | 4.6671333   |\n",
      "|    reward_mean          | 0.042134456 |\n",
      "|    reward_min           | -3.7752855  |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 0.0698      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.51\n",
      "Episode Finished. Sharpe: 1.40\n",
      "Episode Finished. Sharpe: 1.54\n",
      "Episode Finished. Sharpe: 1.44\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 19.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 545         |\n",
      "|    total_timesteps      | 321536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10925718  |\n",
      "|    clip_fraction        | 0.445       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.639      |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.0605     |\n",
      "|    reward               | 0.6347406   |\n",
      "|    reward_max           | 4.471502    |\n",
      "|    reward_mean          | 0.047581103 |\n",
      "|    reward_min           | -3.7043786  |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 0.0677      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.46\n",
      "Episode Finished. Sharpe: 1.50\n",
      "Episode Finished. Sharpe: 1.42\n",
      "Episode Finished. Sharpe: 1.50\n",
      "Episode Finished. Sharpe: 1.47\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 19.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.1067003   |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.8       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.662      |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.0589     |\n",
      "|    reward               | -0.13018678 |\n",
      "|    reward_max           | 4.4572887   |\n",
      "|    reward_mean          | 0.044174526 |\n",
      "|    reward_min           | -3.7517383  |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 0.0832      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.40\n",
      "Episode Finished. Sharpe: 1.44\n",
      "Episode Finished. Sharpe: 1.42\n",
      "Episode Finished. Sharpe: 1.60\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 20         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 589        |\n",
      "|    iterations           | 159        |\n",
      "|    time_elapsed         | 552        |\n",
      "|    total_timesteps      | 325632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.1056045  |\n",
      "|    clip_fraction        | 0.434      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.9      |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.594     |\n",
      "|    n_updates            | 1580       |\n",
      "|    policy_gradient_loss | -0.0676    |\n",
      "|    reward               | 0.7770029  |\n",
      "|    reward_max           | 4.6572027  |\n",
      "|    reward_mean          | 0.04799326 |\n",
      "|    reward_min           | -3.8858175 |\n",
      "|    std                  | 1.67       |\n",
      "|    value_loss           | 0.0786     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.47\n",
      "Episode Finished. Sharpe: 1.48\n",
      "Episode Finished. Sharpe: 1.51\n",
      "Episode Finished. Sharpe: 1.52\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 20.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 556         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09161127  |\n",
      "|    clip_fraction        | 0.431       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.584      |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.0585     |\n",
      "|    reward               | -0.28951168 |\n",
      "|    reward_max           | 4.528716    |\n",
      "|    reward_mean          | 0.047119595 |\n",
      "|    reward_min           | -3.7535625  |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 0.0654      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.44\n",
      "Episode Finished. Sharpe: 1.45\n",
      "Episode Finished. Sharpe: 1.32\n",
      "Episode Finished. Sharpe: 1.49\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 20.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 560         |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.094687335 |\n",
      "|    clip_fraction        | 0.441       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.648      |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.0642     |\n",
      "|    reward               | -0.2559873  |\n",
      "|    reward_max           | 4.564375    |\n",
      "|    reward_mean          | 0.042711493 |\n",
      "|    reward_min           | -3.9217014  |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 0.0715      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.51\n",
      "Episode Finished. Sharpe: 1.45\n",
      "Episode Finished. Sharpe: 1.53\n",
      "Episode Finished. Sharpe: 1.50\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 20.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 588        |\n",
      "|    iterations           | 162        |\n",
      "|    time_elapsed         | 564        |\n",
      "|    total_timesteps      | 331776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09765795 |\n",
      "|    clip_fraction        | 0.421      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.1      |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.59      |\n",
      "|    n_updates            | 1610       |\n",
      "|    policy_gradient_loss | -0.0538    |\n",
      "|    reward               | 0.3900011  |\n",
      "|    reward_max           | 4.440451   |\n",
      "|    reward_mean          | 0.04737206 |\n",
      "|    reward_min           | -3.8455956 |\n",
      "|    std                  | 1.69       |\n",
      "|    value_loss           | 0.0757     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.50\n",
      "Episode Finished. Sharpe: 1.36\n",
      "Episode Finished. Sharpe: 1.45\n",
      "Episode Finished. Sharpe: 1.54\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 20.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 568         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.12783867  |\n",
      "|    clip_fraction        | 0.437       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.564      |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.0534     |\n",
      "|    reward               | -0.93652195 |\n",
      "|    reward_max           | 4.606454    |\n",
      "|    reward_mean          | 0.042494643 |\n",
      "|    reward_min           | -4.002214   |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 0.0687      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.53\n",
      "Episode Finished. Sharpe: 1.55\n",
      "Episode Finished. Sharpe: 1.48\n",
      "Episode Finished. Sharpe: 1.57\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 21.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.07568459  |\n",
      "|    clip_fraction        | 0.409       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.62       |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.0567     |\n",
      "|    reward               | 0.85951614  |\n",
      "|    reward_max           | 4.3526273   |\n",
      "|    reward_mean          | 0.050478246 |\n",
      "|    reward_min           | -3.8965726  |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 0.0912      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.61\n",
      "Episode Finished. Sharpe: 1.44\n",
      "Episode Finished. Sharpe: 1.42\n",
      "Episode Finished. Sharpe: 1.48\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 21.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 576         |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.099873535 |\n",
      "|    clip_fraction        | 0.42        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.3       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.596      |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.0589     |\n",
      "|    reward               | 0.031920176 |\n",
      "|    reward_max           | 4.598884    |\n",
      "|    reward_mean          | 0.044940215 |\n",
      "|    reward_min           | -3.8775778  |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 0.0796      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.62\n",
      "Episode Finished. Sharpe: 1.46\n",
      "Episode Finished. Sharpe: 1.56\n",
      "Episode Finished. Sharpe: 1.51\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 21.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 580         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10636796  |\n",
      "|    clip_fraction        | 0.437       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.65       |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.0628     |\n",
      "|    reward               | 0.9293376   |\n",
      "|    reward_max           | 4.6730485   |\n",
      "|    reward_mean          | 0.048684444 |\n",
      "|    reward_min           | -3.8426213  |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 0.0604      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.45\n",
      "Episode Finished. Sharpe: 1.42\n",
      "Episode Finished. Sharpe: 1.39\n",
      "Episode Finished. Sharpe: 1.48\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 21.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 584         |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11741346  |\n",
      "|    clip_fraction        | 0.452       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.652      |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0581     |\n",
      "|    reward               | 1.2033165   |\n",
      "|    reward_max           | 4.250366    |\n",
      "|    reward_mean          | 0.041615274 |\n",
      "|    reward_min           | -3.8723876  |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 0.0704      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.51\n",
      "Episode Finished. Sharpe: 1.55\n",
      "Episode Finished. Sharpe: 1.28\n",
      "Episode Finished. Sharpe: 1.26\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 21.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 588         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08389203  |\n",
      "|    clip_fraction        | 0.413       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.651      |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0577     |\n",
      "|    reward               | 0.3311529   |\n",
      "|    reward_max           | 4.6573796   |\n",
      "|    reward_mean          | 0.038937524 |\n",
      "|    reward_min           | -3.8704517  |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 0.0721      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.49\n",
      "Episode Finished. Sharpe: 1.48\n",
      "Episode Finished. Sharpe: 1.56\n",
      "Episode Finished. Sharpe: 1.44\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | 21.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 584          |\n",
      "|    iterations           | 169          |\n",
      "|    time_elapsed         | 592          |\n",
      "|    total_timesteps      | 346112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.10884319   |\n",
      "|    clip_fraction        | 0.423        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -58.5        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.654       |\n",
      "|    n_updates            | 1680         |\n",
      "|    policy_gradient_loss | -0.0579      |\n",
      "|    reward               | -0.021539135 |\n",
      "|    reward_max           | 4.5545583    |\n",
      "|    reward_mean          | 0.041590024  |\n",
      "|    reward_min           | -3.915878    |\n",
      "|    std                  | 1.71         |\n",
      "|    value_loss           | 0.102        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 1.47\n",
      "Episode Finished. Sharpe: 1.52\n",
      "Episode Finished. Sharpe: 1.49\n",
      "Episode Finished. Sharpe: 1.44\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 22.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10293093  |\n",
      "|    clip_fraction        | 0.424       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.609      |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.0562     |\n",
      "|    reward               | -0.47558472 |\n",
      "|    reward_max           | 4.6139245   |\n",
      "|    reward_mean          | 0.049119376 |\n",
      "|    reward_min           | -3.822659   |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 0.0753      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.51\n",
      "Episode Finished. Sharpe: 1.58\n",
      "Episode Finished. Sharpe: 1.51\n",
      "Episode Finished. Sharpe: 1.53\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 22.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 600         |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11076222  |\n",
      "|    clip_fraction        | 0.416       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.604      |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.0583     |\n",
      "|    reward               | -1.2063282  |\n",
      "|    reward_max           | 4.6090927   |\n",
      "|    reward_mean          | 0.047612257 |\n",
      "|    reward_min           | -3.8280404  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 0.0817      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.65\n",
      "Episode Finished. Sharpe: 1.59\n",
      "Episode Finished. Sharpe: 1.43\n",
      "Episode Finished. Sharpe: 1.49\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 22.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.12401607  |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.7       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.638      |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.0632     |\n",
      "|    reward               | -0.63264453 |\n",
      "|    reward_max           | 4.6623006   |\n",
      "|    reward_mean          | 0.050138336 |\n",
      "|    reward_min           | -3.8788075  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 0.0892      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.58\n",
      "Episode Finished. Sharpe: 1.51\n",
      "Episode Finished. Sharpe: 1.58\n",
      "Episode Finished. Sharpe: 1.48\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 22.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 582        |\n",
      "|    iterations           | 173        |\n",
      "|    time_elapsed         | 607        |\n",
      "|    total_timesteps      | 354304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0900645  |\n",
      "|    clip_fraction        | 0.393      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.7      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.629     |\n",
      "|    n_updates            | 1720       |\n",
      "|    policy_gradient_loss | -0.0635    |\n",
      "|    reward               | 0.3337147  |\n",
      "|    reward_max           | 4.5033736  |\n",
      "|    reward_mean          | 0.04997953 |\n",
      "|    reward_min           | -3.7801676 |\n",
      "|    std                  | 1.72       |\n",
      "|    value_loss           | 0.0803     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.55\n",
      "Episode Finished. Sharpe: 1.60\n",
      "Episode Finished. Sharpe: 1.58\n",
      "Episode Finished. Sharpe: 1.48\n",
      "Episode Finished. Sharpe: 1.44\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 22.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09802115  |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.619      |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.0605     |\n",
      "|    reward               | 0.46181685  |\n",
      "|    reward_max           | 4.69036     |\n",
      "|    reward_mean          | 0.051187243 |\n",
      "|    reward_min           | -3.9323509  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 0.072       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.63\n",
      "Episode Finished. Sharpe: 1.60\n",
      "Episode Finished. Sharpe: 1.49\n",
      "Episode Finished. Sharpe: 1.54\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 22.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 614         |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.13328533  |\n",
      "|    clip_fraction        | 0.439       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.9       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.635      |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.065      |\n",
      "|    reward               | 0.039266843 |\n",
      "|    reward_max           | 4.6606655   |\n",
      "|    reward_mean          | 0.051882382 |\n",
      "|    reward_min           | -3.9947407  |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 0.0762      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.41\n",
      "Episode Finished. Sharpe: 1.67\n",
      "Episode Finished. Sharpe: 1.49\n",
      "Episode Finished. Sharpe: 1.60\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 22.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.07885501  |\n",
      "|    clip_fraction        | 0.415       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.662      |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.0641     |\n",
      "|    reward               | -0.15346122 |\n",
      "|    reward_max           | 4.598644    |\n",
      "|    reward_mean          | 0.05268723  |\n",
      "|    reward_min           | -3.9347587  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 0.0753      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.61\n",
      "Episode Finished. Sharpe: 1.53\n",
      "Episode Finished. Sharpe: 1.47\n",
      "Episode Finished. Sharpe: 1.55\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 23.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 614         |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.117618136 |\n",
      "|    clip_fraction        | 0.425       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59         |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.641      |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.0587     |\n",
      "|    reward               | 0.82797104  |\n",
      "|    reward_max           | 4.5998654   |\n",
      "|    reward_mean          | 0.04847258  |\n",
      "|    reward_min           | -3.8167086  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 0.0801      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.49\n",
      "Episode Finished. Sharpe: 1.55\n",
      "Episode Finished. Sharpe: 1.58\n",
      "Episode Finished. Sharpe: 1.54\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 23.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 590        |\n",
      "|    iterations           | 178        |\n",
      "|    time_elapsed         | 617        |\n",
      "|    total_timesteps      | 364544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10896394 |\n",
      "|    clip_fraction        | 0.427      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59        |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.672     |\n",
      "|    n_updates            | 1770       |\n",
      "|    policy_gradient_loss | -0.0661    |\n",
      "|    reward               | 0.4822713  |\n",
      "|    reward_max           | 4.992453   |\n",
      "|    reward_mean          | 0.05063262 |\n",
      "|    reward_min           | -3.8416374 |\n",
      "|    std                  | 1.74       |\n",
      "|    value_loss           | 0.061      |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.59\n",
      "Episode Finished. Sharpe: 1.64\n",
      "Episode Finished. Sharpe: 1.58\n",
      "Episode Finished. Sharpe: 1.57\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 23.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 621         |\n",
      "|    total_timesteps      | 366592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.12689035  |\n",
      "|    clip_fraction        | 0.435       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.602      |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.0615     |\n",
      "|    reward               | 0.09313751  |\n",
      "|    reward_max           | 4.729323    |\n",
      "|    reward_mean          | 0.051786274 |\n",
      "|    reward_min           | -3.7304316  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 0.0696      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.48\n",
      "Episode Finished. Sharpe: 1.71\n",
      "Episode Finished. Sharpe: 1.62\n",
      "Episode Finished. Sharpe: 1.58\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 23.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 624         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.19696493  |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.647      |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.0622     |\n",
      "|    reward               | -0.06923518 |\n",
      "|    reward_max           | 4.6937323   |\n",
      "|    reward_mean          | 0.05573374  |\n",
      "|    reward_min           | -3.67937    |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 0.0728      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.64\n",
      "Episode Finished. Sharpe: 1.58\n",
      "Episode Finished. Sharpe: 1.55\n",
      "Episode Finished. Sharpe: 1.51\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 24          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 628         |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.14505032  |\n",
      "|    clip_fraction        | 0.436       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.627      |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.0614     |\n",
      "|    reward               | 0.85246915  |\n",
      "|    reward_max           | 4.550438    |\n",
      "|    reward_mean          | 0.048997696 |\n",
      "|    reward_min           | -3.770096   |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 0.0931      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.50\n",
      "Episode Finished. Sharpe: 1.56\n",
      "Episode Finished. Sharpe: 1.61\n",
      "Episode Finished. Sharpe: 1.60\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 24.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 631         |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.13196746  |\n",
      "|    clip_fraction        | 0.434       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.3       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.621      |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    reward               | -1.220888   |\n",
      "|    reward_max           | 4.65479     |\n",
      "|    reward_mean          | 0.050725717 |\n",
      "|    reward_min           | -3.7651124  |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 0.0801      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.45\n",
      "Episode Finished. Sharpe: 1.50\n",
      "Episode Finished. Sharpe: 1.51\n",
      "Episode Finished. Sharpe: 1.65\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 24.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 590        |\n",
      "|    iterations           | 183        |\n",
      "|    time_elapsed         | 634        |\n",
      "|    total_timesteps      | 374784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12111167 |\n",
      "|    clip_fraction        | 0.426      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.4      |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.666     |\n",
      "|    n_updates            | 1820       |\n",
      "|    policy_gradient_loss | -0.0548    |\n",
      "|    reward               | 0.98536366 |\n",
      "|    reward_max           | 4.6438127  |\n",
      "|    reward_mean          | 0.05003123 |\n",
      "|    reward_min           | -3.8652189 |\n",
      "|    std                  | 1.77       |\n",
      "|    value_loss           | 0.075      |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.57\n",
      "Episode Finished. Sharpe: 1.55\n",
      "Episode Finished. Sharpe: 1.48\n",
      "Episode Finished. Sharpe: 1.55\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 24.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 638         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.118139654 |\n",
      "|    clip_fraction        | 0.435       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.67       |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.062      |\n",
      "|    reward               | 1.0929446   |\n",
      "|    reward_max           | 4.7122126   |\n",
      "|    reward_mean          | 0.045381993 |\n",
      "|    reward_min           | -3.7810645  |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 0.0791      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.57\n",
      "Episode Finished. Sharpe: 1.57\n",
      "Episode Finished. Sharpe: 1.59\n",
      "Episode Finished. Sharpe: 1.47\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 24.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 641         |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.06971148  |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.678      |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.0698     |\n",
      "|    reward               | -0.6795996  |\n",
      "|    reward_max           | 4.5326324   |\n",
      "|    reward_mean          | 0.049509153 |\n",
      "|    reward_min           | -3.8517873  |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 0.0871      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.65\n",
      "Episode Finished. Sharpe: 1.57\n",
      "Episode Finished. Sharpe: 1.57\n",
      "Episode Finished. Sharpe: 1.49\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 24.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 590        |\n",
      "|    iterations           | 186        |\n",
      "|    time_elapsed         | 644        |\n",
      "|    total_timesteps      | 380928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12584469 |\n",
      "|    clip_fraction        | 0.419      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.6      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.643     |\n",
      "|    n_updates            | 1850       |\n",
      "|    policy_gradient_loss | -0.0661    |\n",
      "|    reward               | 0.6501463  |\n",
      "|    reward_max           | 4.427971   |\n",
      "|    reward_mean          | 0.05464819 |\n",
      "|    reward_min           | -3.7301633 |\n",
      "|    std                  | 1.78       |\n",
      "|    value_loss           | 0.076      |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.54\n",
      "Episode Finished. Sharpe: 1.68\n",
      "Episode Finished. Sharpe: 1.52\n",
      "Episode Finished. Sharpe: 1.62\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 24.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 647         |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.13578922  |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.623      |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.0582     |\n",
      "|    reward               | -1.6929015  |\n",
      "|    reward_max           | 4.664756    |\n",
      "|    reward_mean          | 0.044703316 |\n",
      "|    reward_min           | -3.7729945  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 0.0689      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.61\n",
      "Episode Finished. Sharpe: 1.59\n",
      "Episode Finished. Sharpe: 1.55\n",
      "Episode Finished. Sharpe: 1.61\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 24.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 651         |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09149422  |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.661      |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.0677     |\n",
      "|    reward               | 0.4127791   |\n",
      "|    reward_max           | 4.3682256   |\n",
      "|    reward_mean          | 0.061724614 |\n",
      "|    reward_min           | -3.6195478  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 0.0648      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.64\n",
      "Episode Finished. Sharpe: 1.57\n",
      "Episode Finished. Sharpe: 1.70\n",
      "Episode Finished. Sharpe: 1.67\n",
      "Episode Finished. Sharpe: 1.59\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 25          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 655         |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.10470876  |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.659      |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.0591     |\n",
      "|    reward               | -0.22242391 |\n",
      "|    reward_max           | 4.7181664   |\n",
      "|    reward_mean          | 0.05507899  |\n",
      "|    reward_min           | -3.8123596  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 0.0675      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.56\n",
      "Episode Finished. Sharpe: 1.53\n",
      "Episode Finished. Sharpe: 1.68\n",
      "Episode Finished. Sharpe: 1.67\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 25.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 659         |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0973906   |\n",
      "|    clip_fraction        | 0.422       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.622      |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.0589     |\n",
      "|    reward               | -0.48142126 |\n",
      "|    reward_max           | 4.6511507   |\n",
      "|    reward_mean          | 0.056922194 |\n",
      "|    reward_min           | -3.6623073  |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 0.0742      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.62\n",
      "Episode Finished. Sharpe: 1.59\n",
      "Episode Finished. Sharpe: 1.75\n",
      "Episode Finished. Sharpe: 1.60\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 25.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 663         |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.12558018  |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.9       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.702      |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.0608     |\n",
      "|    reward               | -0.20426087 |\n",
      "|    reward_max           | 4.477744    |\n",
      "|    reward_mean          | 0.058919057 |\n",
      "|    reward_min           | -3.7683136  |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 0.0553      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.59\n",
      "Episode Finished. Sharpe: 1.71\n",
      "Episode Finished. Sharpe: 1.61\n",
      "Episode Finished. Sharpe: 1.62\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 25.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.107557006 |\n",
      "|    clip_fraction        | 0.416       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.9       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.633      |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | -0.0598     |\n",
      "|    reward               | 0.5150307   |\n",
      "|    reward_max           | 4.6431055   |\n",
      "|    reward_mean          | 0.056008335 |\n",
      "|    reward_min           | -3.9694035  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 0.0726      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.70\n",
      "Episode Finished. Sharpe: 1.65\n",
      "Episode Finished. Sharpe: 1.62\n",
      "Episode Finished. Sharpe: 1.54\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 26          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 671         |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.07255769  |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.676      |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.0646     |\n",
      "|    reward               | 0.37385756  |\n",
      "|    reward_max           | 4.7981896   |\n",
      "|    reward_mean          | 0.056773275 |\n",
      "|    reward_min           | -3.8176298  |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 0.0665      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.73\n",
      "Episode Finished. Sharpe: 1.70\n",
      "Episode Finished. Sharpe: 1.56\n",
      "Episode Finished. Sharpe: 1.59\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 26.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 675         |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.078722894 |\n",
      "|    clip_fraction        | 0.407       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.639      |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.0682     |\n",
      "|    reward               | 0.53024894  |\n",
      "|    reward_max           | 4.662649    |\n",
      "|    reward_mean          | 0.056714125 |\n",
      "|    reward_min           | -3.818146   |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 0.0915      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.67\n",
      "Episode Finished. Sharpe: 1.55\n",
      "Episode Finished. Sharpe: 1.77\n",
      "Episode Finished. Sharpe: 1.77\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | 26.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 588          |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 679          |\n",
      "|    total_timesteps      | 399360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.100196764  |\n",
      "|    clip_fraction        | 0.43         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -60.1        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.689       |\n",
      "|    n_updates            | 1940         |\n",
      "|    policy_gradient_loss | -0.0643      |\n",
      "|    reward               | -0.041683186 |\n",
      "|    reward_max           | 4.576533     |\n",
      "|    reward_mean          | 0.058618404  |\n",
      "|    reward_min           | -3.802597    |\n",
      "|    std                  | 1.81         |\n",
      "|    value_loss           | 0.0709       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 1.60\n",
      "Episode Finished. Sharpe: 1.73\n",
      "Episode Finished. Sharpe: 1.64\n",
      "Episode Finished. Sharpe: 1.60\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 26.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 587        |\n",
      "|    iterations           | 196        |\n",
      "|    time_elapsed         | 683        |\n",
      "|    total_timesteps      | 401408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.1301142  |\n",
      "|    clip_fraction        | 0.436      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.2      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.67      |\n",
      "|    n_updates            | 1950       |\n",
      "|    policy_gradient_loss | -0.0654    |\n",
      "|    reward               | -0.7076087 |\n",
      "|    reward_max           | 4.7046256  |\n",
      "|    reward_mean          | 0.05570674 |\n",
      "|    reward_min           | -3.7634363 |\n",
      "|    std                  | 1.81       |\n",
      "|    value_loss           | 0.0662     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.73\n",
      "Episode Finished. Sharpe: 1.58\n",
      "Episode Finished. Sharpe: 1.58\n",
      "Episode Finished. Sharpe: 1.70\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 26.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 687         |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.122394696 |\n",
      "|    clip_fraction        | 0.415       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.665      |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | -0.0635     |\n",
      "|    reward               | -0.4332755  |\n",
      "|    reward_max           | 4.7701745   |\n",
      "|    reward_mean          | 0.056127086 |\n",
      "|    reward_min           | -3.6989396  |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 0.0663      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.44\n",
      "Episode Finished. Sharpe: 1.63\n",
      "Episode Finished. Sharpe: 1.66\n",
      "Episode Finished. Sharpe: 1.73\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 26.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 691         |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.105363876 |\n",
      "|    clip_fraction        | 0.409       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.4       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.647      |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.0639     |\n",
      "|    reward               | -1.1215988  |\n",
      "|    reward_max           | 4.710677    |\n",
      "|    reward_mean          | 0.052680567 |\n",
      "|    reward_min           | -3.891034   |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 0.0663      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.57\n",
      "Episode Finished. Sharpe: 1.65\n",
      "Episode Finished. Sharpe: 1.56\n",
      "Episode Finished. Sharpe: 1.82\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 27         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 586        |\n",
      "|    iterations           | 199        |\n",
      "|    time_elapsed         | 695        |\n",
      "|    total_timesteps      | 407552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13866276 |\n",
      "|    clip_fraction        | 0.409      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.4      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.671     |\n",
      "|    n_updates            | 1980       |\n",
      "|    policy_gradient_loss | -0.0626    |\n",
      "|    reward               | 0.31449616 |\n",
      "|    reward_max           | 4.643224   |\n",
      "|    reward_mean          | 0.06032796 |\n",
      "|    reward_min           | -3.7674792 |\n",
      "|    std                  | 1.83       |\n",
      "|    value_loss           | 0.0775     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.55\n",
      "Episode Finished. Sharpe: 1.58\n",
      "Episode Finished. Sharpe: 1.56\n",
      "Episode Finished. Sharpe: 1.75\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 27.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 585        |\n",
      "|    iterations           | 200        |\n",
      "|    time_elapsed         | 699        |\n",
      "|    total_timesteps      | 409600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21939808 |\n",
      "|    clip_fraction        | 0.447      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.5      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.654     |\n",
      "|    n_updates            | 1990       |\n",
      "|    policy_gradient_loss | -0.0423    |\n",
      "|    reward               | 0.54331905 |\n",
      "|    reward_max           | 4.65591    |\n",
      "|    reward_mean          | 0.0521859  |\n",
      "|    reward_min           | -3.951133  |\n",
      "|    std                  | 1.83       |\n",
      "|    value_loss           | 0.0712     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.60\n",
      "Episode Finished. Sharpe: 1.70\n",
      "Episode Finished. Sharpe: 1.64\n",
      "Episode Finished. Sharpe: 1.69\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 27.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 703         |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.16371253  |\n",
      "|    clip_fraction        | 0.437       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.615      |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.0456     |\n",
      "|    reward               | -0.5656855  |\n",
      "|    reward_max           | 4.7493863   |\n",
      "|    reward_mean          | 0.057337742 |\n",
      "|    reward_min           | -3.7965508  |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 0.0738      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.78\n",
      "Episode Finished. Sharpe: 1.67\n",
      "Episode Finished. Sharpe: 1.75\n",
      "Episode Finished. Sharpe: 1.61\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 27.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 707         |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.13145995  |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.588      |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.0505     |\n",
      "|    reward               | -2.6940248  |\n",
      "|    reward_max           | 4.835919    |\n",
      "|    reward_mean          | 0.059957054 |\n",
      "|    reward_min           | -3.8542392  |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 0.0767      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.59\n",
      "Episode Finished. Sharpe: 1.69\n",
      "Episode Finished. Sharpe: 1.69\n",
      "Episode Finished. Sharpe: 1.57\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 27.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 711         |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09576357  |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.664      |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | -0.0616     |\n",
      "|    reward               | -0.0682249  |\n",
      "|    reward_max           | 4.66985     |\n",
      "|    reward_mean          | 0.050630853 |\n",
      "|    reward_min           | -3.7817655  |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 0.0747      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.60\n",
      "Episode Finished. Sharpe: 1.59\n",
      "Episode Finished. Sharpe: 1.68\n",
      "Episode Finished. Sharpe: 1.70\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 27.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 583        |\n",
      "|    iterations           | 204        |\n",
      "|    time_elapsed         | 715        |\n",
      "|    total_timesteps      | 417792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09384319 |\n",
      "|    clip_fraction        | 0.423      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.8      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.673     |\n",
      "|    n_updates            | 2030       |\n",
      "|    policy_gradient_loss | -0.0641    |\n",
      "|    reward               | -1.468292  |\n",
      "|    reward_max           | 4.8442926  |\n",
      "|    reward_mean          | 0.06640237 |\n",
      "|    reward_min           | -3.7783747 |\n",
      "|    std                  | 1.85       |\n",
      "|    value_loss           | 0.0742     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.71\n",
      "Episode Finished. Sharpe: 1.72\n",
      "Episode Finished. Sharpe: 1.73\n",
      "Episode Finished. Sharpe: 1.64\n",
      "Episode Finished. Sharpe: 1.63\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 27.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 583        |\n",
      "|    iterations           | 205        |\n",
      "|    time_elapsed         | 719        |\n",
      "|    total_timesteps      | 419840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15269832 |\n",
      "|    clip_fraction        | 0.416      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.9      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.658     |\n",
      "|    n_updates            | 2040       |\n",
      "|    policy_gradient_loss | -0.0576    |\n",
      "|    reward               | 0.26314    |\n",
      "|    reward_max           | 4.607111   |\n",
      "|    reward_mean          | 0.06002343 |\n",
      "|    reward_min           | -3.8618934 |\n",
      "|    std                  | 1.86       |\n",
      "|    value_loss           | 0.0579     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.77\n",
      "Episode Finished. Sharpe: 1.76\n",
      "Episode Finished. Sharpe: 1.74\n",
      "Episode Finished. Sharpe: 1.69\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 28.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 723         |\n",
      "|    total_timesteps      | 421888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.08770316  |\n",
      "|    clip_fraction        | 0.425       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.66       |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.0591     |\n",
      "|    reward               | -0.26952097 |\n",
      "|    reward_max           | 4.8686433   |\n",
      "|    reward_mean          | 0.063992195 |\n",
      "|    reward_min           | -3.9502268  |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 0.0763      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.66\n",
      "Episode Finished. Sharpe: 1.75\n",
      "Episode Finished. Sharpe: 1.81\n",
      "Episode Finished. Sharpe: 1.74\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 28.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 727         |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.15360452  |\n",
      "|    clip_fraction        | 0.447       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.654      |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | -0.0647     |\n",
      "|    reward               | 0.53937507  |\n",
      "|    reward_max           | 4.740689    |\n",
      "|    reward_mean          | 0.067105584 |\n",
      "|    reward_min           | -3.7025034  |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 0.0684      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.69\n",
      "Episode Finished. Sharpe: 1.77\n",
      "Episode Finished. Sharpe: 1.63\n",
      "Episode Finished. Sharpe: 1.72\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 28.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 731         |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.12916324  |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.674      |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | -0.0556     |\n",
      "|    reward               | 0.160208    |\n",
      "|    reward_max           | 4.655179    |\n",
      "|    reward_mean          | 0.060895998 |\n",
      "|    reward_min           | -3.7493567  |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 0.0621      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.59\n",
      "Episode Finished. Sharpe: 1.64\n",
      "Episode Finished. Sharpe: 1.74\n",
      "Episode Finished. Sharpe: 1.69\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 28.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 582        |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 735        |\n",
      "|    total_timesteps      | 428032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09999921 |\n",
      "|    clip_fraction        | 0.396      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.2      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.661     |\n",
      "|    n_updates            | 2080       |\n",
      "|    policy_gradient_loss | -0.062     |\n",
      "|    reward               | -1.9242959 |\n",
      "|    reward_max           | 4.681983   |\n",
      "|    reward_mean          | 0.05676956 |\n",
      "|    reward_min           | -3.8831515 |\n",
      "|    std                  | 1.87       |\n",
      "|    value_loss           | 0.0788     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.59\n",
      "Episode Finished. Sharpe: 1.74\n",
      "Episode Finished. Sharpe: 1.73\n",
      "Episode Finished. Sharpe: 1.64\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 28.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 738         |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.07727511  |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.671      |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | -0.0619     |\n",
      "|    reward               | -0.14231744 |\n",
      "|    reward_max           | 4.5770073   |\n",
      "|    reward_mean          | 0.06041631  |\n",
      "|    reward_min           | -3.6334634  |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 0.0735      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.67\n",
      "Episode Finished. Sharpe: 1.73\n",
      "Episode Finished. Sharpe: 1.68\n",
      "Episode Finished. Sharpe: 1.75\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 29.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 582        |\n",
      "|    iterations           | 211        |\n",
      "|    time_elapsed         | 742        |\n",
      "|    total_timesteps      | 432128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17899543 |\n",
      "|    clip_fraction        | 0.414      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.3      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.651     |\n",
      "|    n_updates            | 2100       |\n",
      "|    policy_gradient_loss | -0.0609    |\n",
      "|    reward               | -0.253781  |\n",
      "|    reward_max           | 4.89656    |\n",
      "|    reward_mean          | 0.05970247 |\n",
      "|    reward_min           | -3.7930758 |\n",
      "|    std                  | 1.88       |\n",
      "|    value_loss           | 0.0726     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.57\n",
      "Episode Finished. Sharpe: 1.64\n",
      "Episode Finished. Sharpe: 1.76\n",
      "Episode Finished. Sharpe: 1.70\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 29.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 582        |\n",
      "|    iterations           | 212        |\n",
      "|    time_elapsed         | 745        |\n",
      "|    total_timesteps      | 434176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12231507 |\n",
      "|    clip_fraction        | 0.416      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.3      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.695     |\n",
      "|    n_updates            | 2110       |\n",
      "|    policy_gradient_loss | -0.0573    |\n",
      "|    reward               | 1.7507635  |\n",
      "|    reward_max           | 4.6386805  |\n",
      "|    reward_mean          | 0.05660864 |\n",
      "|    reward_min           | -3.7440295 |\n",
      "|    std                  | 1.88       |\n",
      "|    value_loss           | 0.0603     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.53\n",
      "Episode Finished. Sharpe: 1.70\n",
      "Episode Finished. Sharpe: 1.67\n",
      "Episode Finished. Sharpe: 1.62\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 29.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 748         |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.1157006   |\n",
      "|    clip_fraction        | 0.436       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.692      |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.0592     |\n",
      "|    reward               | -0.66225266 |\n",
      "|    reward_max           | 4.5358067   |\n",
      "|    reward_mean          | 0.056999553 |\n",
      "|    reward_min           | -3.7445657  |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 0.0773      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.62\n",
      "Episode Finished. Sharpe: 1.67\n",
      "Episode Finished. Sharpe: 1.72\n",
      "Episode Finished. Sharpe: 1.71\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 29.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 752         |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.102263555 |\n",
      "|    clip_fraction        | 0.432       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.686      |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | -0.0613     |\n",
      "|    reward               | -1.8971193  |\n",
      "|    reward_max           | 4.843122    |\n",
      "|    reward_mean          | 0.05770877  |\n",
      "|    reward_min           | -3.7629395  |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 0.081       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.61\n",
      "Episode Finished. Sharpe: 1.64\n",
      "Episode Finished. Sharpe: 1.68\n",
      "Episode Finished. Sharpe: 1.78\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 29.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 582        |\n",
      "|    iterations           | 215        |\n",
      "|    time_elapsed         | 755        |\n",
      "|    total_timesteps      | 440320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0717673  |\n",
      "|    clip_fraction        | 0.403      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.5      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.693     |\n",
      "|    n_updates            | 2140       |\n",
      "|    policy_gradient_loss | -0.0676    |\n",
      "|    reward               | -0.6268138 |\n",
      "|    reward_max           | 4.5795255  |\n",
      "|    reward_mean          | 0.06183952 |\n",
      "|    reward_min           | -3.65305   |\n",
      "|    std                  | 1.9        |\n",
      "|    value_loss           | 0.0653     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.61\n",
      "Episode Finished. Sharpe: 1.70\n",
      "Episode Finished. Sharpe: 1.81\n",
      "Episode Finished. Sharpe: 1.74\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 29.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 758         |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.12509583  |\n",
      "|    clip_fraction        | 0.424       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.6       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.684      |\n",
      "|    n_updates            | 2150        |\n",
      "|    policy_gradient_loss | -0.0576     |\n",
      "|    reward               | 0.8040439   |\n",
      "|    reward_max           | 4.781578    |\n",
      "|    reward_mean          | 0.060897212 |\n",
      "|    reward_min           | -3.7409332  |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 0.0681      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.67\n",
      "Episode Finished. Sharpe: 1.77\n",
      "Episode Finished. Sharpe: 1.81\n",
      "Episode Finished. Sharpe: 1.81\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 29.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 583        |\n",
      "|    iterations           | 217        |\n",
      "|    time_elapsed         | 762        |\n",
      "|    total_timesteps      | 444416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09804392 |\n",
      "|    clip_fraction        | 0.401      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.7      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.632     |\n",
      "|    n_updates            | 2160       |\n",
      "|    policy_gradient_loss | -0.067     |\n",
      "|    reward               | 0.32691294 |\n",
      "|    reward_max           | 4.6837306  |\n",
      "|    reward_mean          | 0.0631337  |\n",
      "|    reward_min           | -3.8223648 |\n",
      "|    std                  | 1.91       |\n",
      "|    value_loss           | 0.0745     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.70\n",
      "Episode Finished. Sharpe: 1.79\n",
      "Episode Finished. Sharpe: 1.81\n",
      "Episode Finished. Sharpe: 1.72\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 29.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 583        |\n",
      "|    iterations           | 218        |\n",
      "|    time_elapsed         | 765        |\n",
      "|    total_timesteps      | 446464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11366639 |\n",
      "|    clip_fraction        | 0.407      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.8      |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.672     |\n",
      "|    n_updates            | 2170       |\n",
      "|    policy_gradient_loss | -0.0684    |\n",
      "|    reward               | 0.57743716 |\n",
      "|    reward_max           | 4.6011114  |\n",
      "|    reward_mean          | 0.06480316 |\n",
      "|    reward_min           | -3.8193936 |\n",
      "|    std                  | 1.91       |\n",
      "|    value_loss           | 0.0816     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.72\n",
      "Episode Finished. Sharpe: 1.81\n",
      "Episode Finished. Sharpe: 1.78\n",
      "Episode Finished. Sharpe: 1.83\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 30.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 583        |\n",
      "|    iterations           | 219        |\n",
      "|    time_elapsed         | 768        |\n",
      "|    total_timesteps      | 448512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20317142 |\n",
      "|    clip_fraction        | 0.411      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.9      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.659     |\n",
      "|    n_updates            | 2180       |\n",
      "|    policy_gradient_loss | -0.0452    |\n",
      "|    reward               | 1.1019194  |\n",
      "|    reward_max           | 4.762938   |\n",
      "|    reward_mean          | 0.06496461 |\n",
      "|    reward_min           | -3.9503012 |\n",
      "|    std                  | 1.92       |\n",
      "|    value_loss           | 0.0599     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.75\n",
      "Episode Finished. Sharpe: 1.72\n",
      "Episode Finished. Sharpe: 1.89\n",
      "Episode Finished. Sharpe: 1.67\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 30.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 772         |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.118855156 |\n",
      "|    clip_fraction        | 0.422       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62         |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.693      |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | -0.0538     |\n",
      "|    reward               | 0.49041408  |\n",
      "|    reward_max           | 4.5747557   |\n",
      "|    reward_mean          | 0.068491556 |\n",
      "|    reward_min           | -3.7384892  |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 0.0748      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.76\n",
      "Episode Finished. Sharpe: 1.68\n",
      "Episode Finished. Sharpe: 1.83\n",
      "Episode Finished. Sharpe: 1.67\n",
      "Episode Finished. Sharpe: 1.78\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 30.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 775         |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.1021633   |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62         |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.681      |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | -0.0562     |\n",
      "|    reward               | -0.21995617 |\n",
      "|    reward_max           | 4.752766    |\n",
      "|    reward_mean          | 0.06356534  |\n",
      "|    reward_min           | -3.670473   |\n",
      "|    std                  | 1.93        |\n",
      "|    value_loss           | 0.0699      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.71\n",
      "Episode Finished. Sharpe: 1.73\n",
      "Episode Finished. Sharpe: 1.72\n",
      "Episode Finished. Sharpe: 1.73\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 30.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 583        |\n",
      "|    iterations           | 222        |\n",
      "|    time_elapsed         | 778        |\n",
      "|    total_timesteps      | 454656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11652602 |\n",
      "|    clip_fraction        | 0.418      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.1      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.694     |\n",
      "|    n_updates            | 2210       |\n",
      "|    policy_gradient_loss | -0.0678    |\n",
      "|    reward               | 0.7814821  |\n",
      "|    reward_max           | 4.699147   |\n",
      "|    reward_mean          | 0.06596115 |\n",
      "|    reward_min           | -3.711599  |\n",
      "|    std                  | 1.93       |\n",
      "|    value_loss           | 0.0605     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.78\n",
      "Episode Finished. Sharpe: 1.74\n",
      "Episode Finished. Sharpe: 1.84\n",
      "Episode Finished. Sharpe: 1.78\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 30.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 782         |\n",
      "|    total_timesteps      | 456704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0996913   |\n",
      "|    clip_fraction        | 0.425       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.663      |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | -0.0674     |\n",
      "|    reward               | -0.41514322 |\n",
      "|    reward_max           | 4.8301816   |\n",
      "|    reward_mean          | 0.067039356 |\n",
      "|    reward_min           | -3.7657418  |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 0.0938      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.76\n",
      "Episode Finished. Sharpe: 1.69\n",
      "Episode Finished. Sharpe: 1.77\n",
      "Episode Finished. Sharpe: 1.77\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 30.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 785         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.12037234  |\n",
      "|    clip_fraction        | 0.409       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.3       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.708      |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | -0.0677     |\n",
      "|    reward               | -0.23849176 |\n",
      "|    reward_max           | 4.75374     |\n",
      "|    reward_mean          | 0.064315364 |\n",
      "|    reward_min           | -3.8075318  |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 0.0584      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.78\n",
      "Episode Finished. Sharpe: 1.78\n",
      "Episode Finished. Sharpe: 1.75\n",
      "Episode Finished. Sharpe: 1.92\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 31.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 584        |\n",
      "|    iterations           | 225        |\n",
      "|    time_elapsed         | 788        |\n",
      "|    total_timesteps      | 460800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13420095 |\n",
      "|    clip_fraction        | 0.396      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.3      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.704     |\n",
      "|    n_updates            | 2240       |\n",
      "|    policy_gradient_loss | -0.0619    |\n",
      "|    reward               | 0.3586788  |\n",
      "|    reward_max           | 4.8240786  |\n",
      "|    reward_mean          | 0.06853387 |\n",
      "|    reward_min           | -3.7528796 |\n",
      "|    std                  | 1.95       |\n",
      "|    value_loss           | 0.0615     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.72\n",
      "Episode Finished. Sharpe: 1.75\n",
      "Episode Finished. Sharpe: 1.65\n",
      "Episode Finished. Sharpe: 1.73\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 31.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 792         |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.15545014  |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.4       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.664      |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.0498     |\n",
      "|    reward               | -0.77984244 |\n",
      "|    reward_max           | 4.7775693   |\n",
      "|    reward_mean          | 0.061708108 |\n",
      "|    reward_min           | -3.6853895  |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 0.0663      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.78\n",
      "Episode Finished. Sharpe: 1.83\n",
      "Episode Finished. Sharpe: 1.72\n",
      "Episode Finished. Sharpe: 1.77\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 31.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 795         |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.124649644 |\n",
      "|    clip_fraction        | 0.427       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.632      |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.0559     |\n",
      "|    reward               | 1.0004534   |\n",
      "|    reward_max           | 4.589508    |\n",
      "|    reward_mean          | 0.066380545 |\n",
      "|    reward_min           | -3.6235404  |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 0.0836      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.84\n",
      "Episode Finished. Sharpe: 1.85\n",
      "Episode Finished. Sharpe: 1.79\n",
      "Episode Finished. Sharpe: 1.80\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 31.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 798         |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.105843365 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.7        |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.0598     |\n",
      "|    reward               | -0.1453013  |\n",
      "|    reward_max           | 4.890983    |\n",
      "|    reward_mean          | 0.06949584  |\n",
      "|    reward_min           | -3.7601633  |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 0.0754      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.77\n",
      "Episode Finished. Sharpe: 1.87\n",
      "Episode Finished. Sharpe: 1.75\n",
      "Episode Finished. Sharpe: 1.85\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 31.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 802         |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.101831764 |\n",
      "|    clip_fraction        | 0.426       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.697      |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.0665     |\n",
      "|    reward               | 1.0050075   |\n",
      "|    reward_max           | 4.6453953   |\n",
      "|    reward_mean          | 0.06812597  |\n",
      "|    reward_min           | -3.6721823  |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 0.0553      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.81\n",
      "Episode Finished. Sharpe: 1.85\n",
      "Episode Finished. Sharpe: 1.71\n",
      "Episode Finished. Sharpe: 1.86\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 31.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 584        |\n",
      "|    iterations           | 230        |\n",
      "|    time_elapsed         | 805        |\n",
      "|    total_timesteps      | 471040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08281833 |\n",
      "|    clip_fraction        | 0.394      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.7      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.706     |\n",
      "|    n_updates            | 2290       |\n",
      "|    policy_gradient_loss | -0.063     |\n",
      "|    reward               | 1.3622783  |\n",
      "|    reward_max           | 4.750056   |\n",
      "|    reward_mean          | 0.06762134 |\n",
      "|    reward_min           | -3.840091  |\n",
      "|    std                  | 1.98       |\n",
      "|    value_loss           | 0.058      |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.75\n",
      "Episode Finished. Sharpe: 1.73\n",
      "Episode Finished. Sharpe: 1.85\n",
      "Episode Finished. Sharpe: 1.81\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 32         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 584        |\n",
      "|    iterations           | 231        |\n",
      "|    time_elapsed         | 808        |\n",
      "|    total_timesteps      | 473088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.1258648  |\n",
      "|    clip_fraction        | 0.428      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.9      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.664     |\n",
      "|    n_updates            | 2300       |\n",
      "|    policy_gradient_loss | -0.0435    |\n",
      "|    reward               | 0.42605343 |\n",
      "|    reward_max           | 4.620718   |\n",
      "|    reward_mean          | 0.06465525 |\n",
      "|    reward_min           | -3.7444081 |\n",
      "|    std                  | 1.99       |\n",
      "|    value_loss           | 0.0657     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.77\n",
      "Episode Finished. Sharpe: 1.77\n",
      "Episode Finished. Sharpe: 1.74\n",
      "Episode Finished. Sharpe: 1.72\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 32          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 812         |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.11522323  |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.707      |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.0666     |\n",
      "|    reward               | -0.12129868 |\n",
      "|    reward_max           | 4.7972245   |\n",
      "|    reward_mean          | 0.061948065 |\n",
      "|    reward_min           | -3.751969   |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 0.0656      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.86\n",
      "Episode Finished. Sharpe: 1.84\n",
      "Episode Finished. Sharpe: 1.82\n",
      "Episode Finished. Sharpe: 1.84\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 32.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 815         |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.093311876 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.679      |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.0644     |\n",
      "|    reward               | -0.34521785 |\n",
      "|    reward_max           | 4.8312244   |\n",
      "|    reward_mean          | 0.07463938  |\n",
      "|    reward_min           | -3.6393228  |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 0.0768      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.92\n",
      "Episode Finished. Sharpe: 1.68\n",
      "Episode Finished. Sharpe: 1.88\n",
      "Episode Finished. Sharpe: 1.77\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 32.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 818         |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.13536133  |\n",
      "|    clip_fraction        | 0.43        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.693      |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.0574     |\n",
      "|    reward               | -1.1174091  |\n",
      "|    reward_max           | 4.9763045   |\n",
      "|    reward_mean          | 0.064136446 |\n",
      "|    reward_min           | -3.7896461  |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 0.0599      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.86\n",
      "Episode Finished. Sharpe: 1.69\n",
      "Episode Finished. Sharpe: 1.76\n",
      "Episode Finished. Sharpe: 1.81\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 504          |\n",
      "|    ep_rew_mean          | 32.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 585          |\n",
      "|    iterations           | 235          |\n",
      "|    time_elapsed         | 822          |\n",
      "|    total_timesteps      | 481280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0958112    |\n",
      "|    clip_fraction        | 0.41         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -63          |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.67        |\n",
      "|    n_updates            | 2340         |\n",
      "|    policy_gradient_loss | -0.0616      |\n",
      "|    reward               | -0.040207565 |\n",
      "|    reward_max           | 4.738812     |\n",
      "|    reward_mean          | 0.06872148   |\n",
      "|    reward_min           | -3.8157747   |\n",
      "|    std                  | 1.99         |\n",
      "|    value_loss           | 0.0915       |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 1.93\n",
      "Episode Finished. Sharpe: 1.88\n",
      "Episode Finished. Sharpe: 1.82\n",
      "Episode Finished. Sharpe: 1.81\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 32.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 585        |\n",
      "|    iterations           | 236        |\n",
      "|    time_elapsed         | 825        |\n",
      "|    total_timesteps      | 483328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09779932 |\n",
      "|    clip_fraction        | 0.402      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63        |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.677     |\n",
      "|    n_updates            | 2350       |\n",
      "|    policy_gradient_loss | -0.0622    |\n",
      "|    reward               | 0.26206076 |\n",
      "|    reward_max           | 4.9013     |\n",
      "|    reward_mean          | 0.06944123 |\n",
      "|    reward_min           | -3.6949487 |\n",
      "|    std                  | 2          |\n",
      "|    value_loss           | 0.0835     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.71\n",
      "Episode Finished. Sharpe: 1.76\n",
      "Episode Finished. Sharpe: 1.92\n",
      "Episode Finished. Sharpe: 1.73\n",
      "Episode Finished. Sharpe: 1.80\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 33.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 828         |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.094159916 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.1       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.711      |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.0668     |\n",
      "|    reward               | 0.29255673  |\n",
      "|    reward_max           | 4.653185    |\n",
      "|    reward_mean          | 0.06985898  |\n",
      "|    reward_min           | -3.7447982  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 0.0626      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.86\n",
      "Episode Finished. Sharpe: 1.82\n",
      "Episode Finished. Sharpe: 1.91\n",
      "Episode Finished. Sharpe: 1.86\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 33.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 585        |\n",
      "|    iterations           | 238        |\n",
      "|    time_elapsed         | 832        |\n",
      "|    total_timesteps      | 487424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08280224 |\n",
      "|    clip_fraction        | 0.413      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.2      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.697     |\n",
      "|    n_updates            | 2370       |\n",
      "|    policy_gradient_loss | -0.0616    |\n",
      "|    reward               | 0.17067131 |\n",
      "|    reward_max           | 4.743845   |\n",
      "|    reward_mean          | 0.07358672 |\n",
      "|    reward_min           | -3.7495065 |\n",
      "|    std                  | 2.01       |\n",
      "|    value_loss           | 0.0835     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.82\n",
      "Episode Finished. Sharpe: 1.83\n",
      "Episode Finished. Sharpe: 1.80\n",
      "Episode Finished. Sharpe: 1.83\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 33.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 836         |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.09292825  |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.7        |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -0.0655     |\n",
      "|    reward               | 0.020598428 |\n",
      "|    reward_max           | 4.6269417   |\n",
      "|    reward_mean          | 0.07211396  |\n",
      "|    reward_min           | -3.9508672  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 0.0668      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.69\n",
      "Episode Finished. Sharpe: 1.76\n",
      "Episode Finished. Sharpe: 1.87\n",
      "Episode Finished. Sharpe: 1.67\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 33.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 584        |\n",
      "|    iterations           | 240        |\n",
      "|    time_elapsed         | 840        |\n",
      "|    total_timesteps      | 491520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.1351754  |\n",
      "|    clip_fraction        | 0.413      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.4      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.702     |\n",
      "|    n_updates            | 2390       |\n",
      "|    policy_gradient_loss | -0.0616    |\n",
      "|    reward               | 0.7220102  |\n",
      "|    reward_max           | 4.7990904  |\n",
      "|    reward_mean          | 0.0626971  |\n",
      "|    reward_min           | -3.8027992 |\n",
      "|    std                  | 2.02       |\n",
      "|    value_loss           | 0.0556     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.83\n",
      "Episode Finished. Sharpe: 1.85\n",
      "Episode Finished. Sharpe: 1.86\n",
      "Episode Finished. Sharpe: 1.68\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 33.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 844         |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.06494759  |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.706      |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.0645     |\n",
      "|    reward               | 0.6234996   |\n",
      "|    reward_max           | 4.7479773   |\n",
      "|    reward_mean          | 0.069571204 |\n",
      "|    reward_min           | -3.800048   |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 0.0804      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.87\n",
      "Episode Finished. Sharpe: 1.95\n",
      "Episode Finished. Sharpe: 1.75\n",
      "Episode Finished. Sharpe: 1.87\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 33.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 848         |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.097405046 |\n",
      "|    clip_fraction        | 0.401       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.664      |\n",
      "|    n_updates            | 2410        |\n",
      "|    policy_gradient_loss | -0.0569     |\n",
      "|    reward               | 0.03562921  |\n",
      "|    reward_max           | 4.881965    |\n",
      "|    reward_mean          | 0.0711838   |\n",
      "|    reward_min           | -3.8106985  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 0.0739      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.86\n",
      "Episode Finished. Sharpe: 1.77\n",
      "Episode Finished. Sharpe: 1.86\n",
      "Episode Finished. Sharpe: 1.82\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 33.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 852         |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.123189    |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.698      |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.0603     |\n",
      "|    reward               | -0.09956645 |\n",
      "|    reward_max           | 4.7946754   |\n",
      "|    reward_mean          | 0.07137596  |\n",
      "|    reward_min           | -3.6156445  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 0.0637      |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.88\n",
      "Episode Finished. Sharpe: 1.69\n",
      "Episode Finished. Sharpe: 1.75\n",
      "Episode Finished. Sharpe: 1.75\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 33.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 583        |\n",
      "|    iterations           | 244        |\n",
      "|    time_elapsed         | 856        |\n",
      "|    total_timesteps      | 499712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.1685854  |\n",
      "|    clip_fraction        | 0.432      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.6      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.655     |\n",
      "|    n_updates            | 2430       |\n",
      "|    policy_gradient_loss | -0.0581    |\n",
      "|    reward               | 0.8934792  |\n",
      "|    reward_max           | 4.7311983  |\n",
      "|    reward_mean          | 0.06592489 |\n",
      "|    reward_min           | -3.6934922 |\n",
      "|    std                  | 2.03       |\n",
      "|    value_loss           | 0.0478     |\n",
      "----------------------------------------\n",
      "Episode Finished. Sharpe: 1.86\n",
      "Episode Finished. Sharpe: 1.92\n",
      "Episode Finished. Sharpe: 1.80\n",
      "Episode Finished. Sharpe: 1.89\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 504        |\n",
      "|    ep_rew_mean          | 34.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 582        |\n",
      "|    iterations           | 245        |\n",
      "|    time_elapsed         | 860        |\n",
      "|    total_timesteps      | 501760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14150396 |\n",
      "|    clip_fraction        | 0.42       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.7      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.698     |\n",
      "|    n_updates            | 2440       |\n",
      "|    policy_gradient_loss | -0.0556    |\n",
      "|    reward               | -1.153724  |\n",
      "|    reward_max           | 4.843526   |\n",
      "|    reward_mean          | 0.06909073 |\n",
      "|    reward_min           | -3.7540972 |\n",
      "|    std                  | 2.04       |\n",
      "|    value_loss           | 0.0667     |\n",
      "----------------------------------------\n",
      "PPO Training Finished!\n"
     ]
    }
   ],
   "source": [
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "# We assume 'e_train_gym' is already created from your previous steps\n",
    "\n",
    "print(\"Starting PPO Training...\")\n",
    "\n",
    "# 1. Initialize the Agent using the SAME environment\n",
    "agent = DRLAgent(env=e_train_gym)\n",
    "\n",
    "# 2. Get the PPO Model (instead of A2C)\n",
    "# ent_coef=0.01 encourages exploration (prevents getting stuck)\n",
    "model_ppo = agent.get_model(\"ppo\", model_kwargs = {\"ent_coef\": 0.01}) \n",
    "\n",
    "# 3. Train\n",
    "# PPO often benefits from slightly longer training than A2C\n",
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                                tb_log_name=\"ppo_portfolio\",\n",
    "                                total_timesteps=500000)\n",
    "\n",
    "print(\"PPO Training Finished!\")\n",
    "\n",
    "# 4. Save\n",
    "model_ppo.save(\"trained_portfolio_agent_ppo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb6858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Preparando datos para Q1 2023 (2023-01-01 a 2024-01-01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (14529, 8)\n",
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n",
      "2. Calculando Covarianzas...\n",
      "Días de Trading en Q1: 249\n",
      "3. Ejecutando simulación...\n",
      "Episode Finished. Sharpe: 1.12\n",
      "4. Generando comparación contra S&P 500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (250, 8)\n",
      "--- RESULTADOS Q1 2023 ---\n",
      "Rendimiento Agente:   12.48%\n",
      "Rendimiento S&P 500:  23.80%\n",
      "⚠️ Por debajo del mercado por: -11.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicor\\AppData\\Local\\Temp\\ipykernel_35608\\1054524121.py:132: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
    "from finrl import config_tickers\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURACIÓN DE FECHAS (Q1 2023)\n",
    "# ==============================================================================\n",
    "TEST_START_DATE = '2024-01-01'\n",
    "TEST_END_DATE = '2025-01-01' # Hasta el 1 de Abril para incluir todo Marzo\n",
    "\n",
    "print(f\"1. Preparando datos para Q1 2023 ({TEST_START_DATE} a {TEST_END_DATE})...\")\n",
    "\n",
    "# Descargamos desde 2022 para tener el contexto (lookback) necesario\n",
    "ticker_list = [ticker for ticker in config_tickers.DOW_30_TICKER if ticker != 'WBA']\n",
    "df_q1 = YahooDownloader(start_date='2022-01-01', \n",
    "                        end_date=TEST_END_DATE, \n",
    "                        ticker_list=ticker_list).fetch_data()\n",
    "\n",
    "# Indicadores\n",
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list=['macd', 'rsi_30', 'cci_30', 'dx_30'],\n",
    "                     use_turbulence=True,\n",
    "                     user_defined_feature=False)\n",
    "df_q1 = fe.preprocess_data(df_q1)\n",
    "\n",
    "# Ordenar\n",
    "df_q1 = df_q1.sort_values(['date','tic'], ignore_index=True)\n",
    "df_q1.index = df_q1.date.factorize()[0]\n",
    "\n",
    "# Covarianzas\n",
    "print(\"2. Calculando Covarianzas...\")\n",
    "cov_list = []\n",
    "dates_with_cov = []\n",
    "lookback = 252 \n",
    "unique_dates = df_q1.date.unique()\n",
    "\n",
    "for i in range(lookback, len(unique_dates)):\n",
    "    current_date = unique_dates[i]\n",
    "    data_lookback = df_q1.loc[i-lookback:i, :]\n",
    "    price_lookback = data_lookback.pivot_table(index='date', columns='tic', values='close')\n",
    "    return_lookback = price_lookback.pct_change().dropna()\n",
    "    covs = return_lookback.cov().values \n",
    "    cov_list.append(covs)\n",
    "    dates_with_cov.append(current_date)\n",
    "\n",
    "# Filtrar para el periodo de prueba exacto\n",
    "df_test_q1 = df_q1[df_q1.date.isin(dates_with_cov)].copy()\n",
    "# Aseguramos que solo tomamos fechas >= 2023-01-01 para la simulación\n",
    "df_test_q1 = df_test_q1[df_test_q1.date >= TEST_START_DATE]\n",
    "\n",
    "cov_dict = dict(zip(dates_with_cov, cov_list))\n",
    "df_test_q1['cov_list'] = df_test_q1['date'].map(cov_dict)\n",
    "\n",
    "df_test_q1 = df_test_q1.sort_values(['date', 'tic'], ignore_index=True)\n",
    "df_test_q1.index = df_test_q1.date.factorize()[0]\n",
    "\n",
    "print(f\"Días de Trading en Q1: {len(df_test_q1.index.unique())}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. EJECUTAR AGENTE EN Q1\n",
    "# ==============================================================================\n",
    "print(\"3. Ejecutando simulación...\")\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": len(ticker_list), \n",
    "    \"stock_dim\": len(ticker_list), \n",
    "    \"tech_indicator_list\": ['macd', 'rsi_30', 'cci_30', 'dx_30'], \n",
    "    \"action_space\": len(ticker_list), \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"risk_free_rate\": 0.0375 # Tu tasa FED\n",
    "}\n",
    "\n",
    "env_q1 = StockPortfolioEnv(df=df_test_q1, **env_kwargs)\n",
    "obs, _ = env_q1.reset()\n",
    "done = False\n",
    "\n",
    "# Asegúrate de tener tu modelo cargado (ej: model = PPO.load(\"...\"))\n",
    "# Si ya lo tienes en memoria, usa 'model' o 'model_a2c' / 'model_ppo'\n",
    "while not done:\n",
    "    action, _states = model_ppo.predict(obs, deterministic=True) # Cambia 'model_ppo' si usas otro nombre\n",
    "    obs, rewards, done, truncated, info = env_q1.step(action)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. COMPARACIÓN CONTRA S&P 500\n",
    "# ==============================================================================\n",
    "print(\"4. Generando comparación contra S&P 500...\")\n",
    "\n",
    "# Resultados del Agente\n",
    "df_result_q1 = pd.DataFrame(env_q1.asset_memory)\n",
    "df_result_q1.columns = ['account_value']\n",
    "df_result_q1['date'] = env_q1.date_memory\n",
    "df_result_q1['daily_return'] = df_result_q1['account_value'].pct_change()\n",
    "df_result_q1['cumulative_return'] = (1 + df_result_q1['daily_return']).cumprod()\n",
    "\n",
    "# Descargar Benchmark S&P 500 para Q1\n",
    "baseline_df = YahooDownloader(start_date=TEST_START_DATE, \n",
    "                              end_date=TEST_END_DATE, \n",
    "                              ticker_list=['^GSPC']).fetch_data()\n",
    "\n",
    "baseline_df = baseline_df.sort_values('date')\n",
    "# Alinear fechas\n",
    "baseline_df = baseline_df[baseline_df.date.isin(df_result_q1.date.unique())]\n",
    "baseline_df['daily_return'] = baseline_df['close'].pct_change().fillna(0)\n",
    "baseline_df['cumulative_return'] = (1 + baseline_df['daily_return']).cumprod()\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. GRÁFICO Y ESTADÍSTICAS\n",
    "# ==============================================================================\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Agente\n",
    "plt.plot(df_result_q1['date'], df_result_q1['cumulative_return'], \n",
    "         label='Tu Agente (IA)', color='green', linewidth=2)\n",
    "\n",
    "# S&P 500\n",
    "limit = min(len(df_result_q1), len(baseline_df))\n",
    "plt.plot(df_result_q1['date'][:limit], baseline_df['cumulative_return'][:limit], \n",
    "         label='S&P 500 (Benchmark)', color='grey', linestyle='--')\n",
    "\n",
    "plt.title('Primer Trimestre 2023: IA vs S&P 500', fontsize=16)\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Retorno Acumulado')\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Métricas Finales Q1\n",
    "agent_ret_q1 = (df_result_q1['cumulative_return'].iloc[-1] - 1) * 100\n",
    "sp500_ret_q1 = (baseline_df['cumulative_return'].iloc[-1] - 1) * 100\n",
    "\n",
    "print(f\"--- RESULTADOS Q1 2023 ---\")\n",
    "print(f\"Rendimiento Agente:   {agent_ret_q1:.2f}%\")\n",
    "print(f\"Rendimiento S&P 500:  {sp500_ret_q1:.2f}%\")\n",
    "delta = agent_ret_q1 - sp500_ret_q1\n",
    "if delta > 0:\n",
    "    print(f\"✅ Superaste al mercado por: {delta:.2f}%\")\n",
    "else:\n",
    "    print(f\"⚠️ Por debajo del mercado por: {delta:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f2e9234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando con 10 acciones seleccionadas.\n",
      "\n",
      "1. Descargando Datos de Entrenamiento (Hasta 2025)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (25160, 8)\n",
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n",
      "Calculando Covarianzas (Entrenamiento)...\n",
      "\n",
      "2. Entrenando Nuevo Modelo...\n",
      "{'ent_coef': 0.01, 'n_steps': 2048}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 941         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 2           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.19170164  |\n",
      "|    reward_max      | 9.346372    |\n",
      "|    reward_mean     | 0.022023974 |\n",
      "|    reward_min      | -11.082478  |\n",
      "------------------------------------\n",
      "Episode Finished. Sharpe: 1.17\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 46.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 766         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015573643 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.6       |\n",
      "|    explained_variance   | -0.0633     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.925       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    reward               | 0.022657672 |\n",
      "|    reward_max           | 8.725822    |\n",
      "|    reward_mean          | 0.018375471 |\n",
      "|    reward_min           | -12.131803  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.92        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.10\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 42.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018093273 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.6       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.96        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0496     |\n",
      "|    reward               | -0.92627954 |\n",
      "|    reward_max           | 9.280606    |\n",
      "|    reward_mean          | 0.018127687 |\n",
      "|    reward_min           | -11.715736  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.13        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.04\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.26e+03     |\n",
      "|    ep_rew_mean          | 37.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 697          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.018098354  |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -15.7        |\n",
      "|    explained_variance   | 0.263        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.365        |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0457      |\n",
      "|    reward               | -0.032264564 |\n",
      "|    reward_max           | 8.234259     |\n",
      "|    reward_mean          | 0.016284507  |\n",
      "|    reward_min           | -11.479968   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.61         |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 1.08\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 37.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017733157 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.7       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.253       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0499     |\n",
      "|    reward               | -0.18898237 |\n",
      "|    reward_max           | 9.073789    |\n",
      "|    reward_mean          | 0.010219044 |\n",
      "|    reward_min           | -11.020574  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.11\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 37.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019286595 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.7       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.48        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0528     |\n",
      "|    reward               | 0.14564276  |\n",
      "|    reward_max           | 3.9978547   |\n",
      "|    reward_mean          | 0.02032096  |\n",
      "|    reward_min           | -4.2026772  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.57        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.07\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.26e+03     |\n",
      "|    ep_rew_mean          | 37.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 642          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.022074576  |\n",
      "|    clip_fraction        | 0.241        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -15.7        |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.584        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0559      |\n",
      "|    reward               | -0.2881284   |\n",
      "|    reward_max           | 8.850204     |\n",
      "|    reward_mean          | 0.0072015105 |\n",
      "|    reward_min           | -12.884307   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.53         |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 1.05\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 36.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 627         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01989984  |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.8       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.96        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0502     |\n",
      "|    reward               | -1.4898064  |\n",
      "|    reward_max           | 9.955555    |\n",
      "|    reward_mean          | 0.021744449 |\n",
      "|    reward_min           | -13.59111   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.13\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 37.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020094575 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.8       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.11        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0547     |\n",
      "|    reward               | 0.16118391  |\n",
      "|    reward_max           | 9.374865    |\n",
      "|    reward_mean          | 0.01917549  |\n",
      "|    reward_min           | -10.4610405 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.44        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.11\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 37.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 601         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02186039  |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.8       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.329       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0555     |\n",
      "|    reward               | 0.42435664  |\n",
      "|    reward_max           | 8.567143    |\n",
      "|    reward_mean          | 0.012025882 |\n",
      "|    reward_min           | -10.93521   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 37.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022248417 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.8       |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.668       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0572     |\n",
      "|    reward               | 0.0502447   |\n",
      "|    reward_max           | 9.612387    |\n",
      "|    reward_mean          | 0.015199478 |\n",
      "|    reward_min           | -10.814528  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.92        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.09\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 36.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025522407 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.8       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0559     |\n",
      "|    reward               | 0.15219104  |\n",
      "|    reward_max           | 8.146377    |\n",
      "|    reward_mean          | 0.017555498 |\n",
      "|    reward_min           | -12.033518  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.83        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.14\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 37.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 578         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027977206 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.8       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.96        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0578     |\n",
      "|    reward               | -0.58876234 |\n",
      "|    reward_max           | 8.449902    |\n",
      "|    reward_mean          | 0.011627197 |\n",
      "|    reward_min           | -12.852989  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.73        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.97\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 35.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 576         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025830667 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.8       |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.058      |\n",
      "|    reward               | 0.75692105  |\n",
      "|    reward_max           | 8.881512    |\n",
      "|    reward_mean          | 0.022090456 |\n",
      "|    reward_min           | -12.874341  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.57        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.11\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 36.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 572         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029374216 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.8       |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.405       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0542     |\n",
      "|    reward               | 0.35489416  |\n",
      "|    reward_max           | 8.987544    |\n",
      "|    reward_mean          | 0.009853239 |\n",
      "|    reward_min           | -12.798024  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.47        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.05\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 35.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 575         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029187322 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.8       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.313       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0603     |\n",
      "|    reward               | -0.08129248 |\n",
      "|    reward_max           | 9.895253    |\n",
      "|    reward_mean          | 0.010809541 |\n",
      "|    reward_min           | -12.674485  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.45        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.11\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 36          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 578         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03620834  |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.9       |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.336       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0596     |\n",
      "|    reward               | 0.1373651   |\n",
      "|    reward_max           | 3.533777    |\n",
      "|    reward_mean          | 0.021078782 |\n",
      "|    reward_min           | -5.649527   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.13\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 36.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036470007 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.9       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0627     |\n",
      "|    reward               | -0.35354635 |\n",
      "|    reward_max           | 8.306539    |\n",
      "|    reward_mean          | 0.019325446 |\n",
      "|    reward_min           | -12.392461  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.806       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.08\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 36.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03653683  |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.9       |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.169       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0576     |\n",
      "|    reward               | -0.2721241  |\n",
      "|    reward_max           | 8.423382    |\n",
      "|    reward_mean          | 0.015433643 |\n",
      "|    reward_min           | -11.290622  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.05\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 36.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037899047 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.9       |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0596     |\n",
      "|    reward               | 0.4135781   |\n",
      "|    reward_max           | 7.991121    |\n",
      "|    reward_mean          | 0.009501679 |\n",
      "|    reward_min           | -12.950474  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 36.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038003735 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.9       |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.153       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0632     |\n",
      "|    reward               | -0.85612124 |\n",
      "|    reward_max           | 9.204033    |\n",
      "|    reward_mean          | 0.019165907 |\n",
      "|    reward_min           | -13.204611  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.945       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.11\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.26e+03     |\n",
      "|    ep_rew_mean          | 36.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 591          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.04100426   |\n",
      "|    clip_fraction        | 0.346        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -15.9        |\n",
      "|    explained_variance   | 0.913        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0726       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0615      |\n",
      "|    reward               | 0.2957206    |\n",
      "|    reward_max           | 8.27512      |\n",
      "|    reward_mean          | 0.0128067685 |\n",
      "|    reward_min           | -10.5656595  |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 0.872        |\n",
      "------------------------------------------\n",
      "Episode Finished. Sharpe: 1.03\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 36          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04222781  |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -15.9       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0602     |\n",
      "|    reward               | 1.0416195   |\n",
      "|    reward_max           | 9.135201    |\n",
      "|    reward_mean          | 0.025970688 |\n",
      "|    reward_min           | -13.133977  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 0.755       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 1.18\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 36.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03734544  |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16         |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0208      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0627     |\n",
      "|    reward               | 2.6300502   |\n",
      "|    reward_max           | 9.092759    |\n",
      "|    reward_mean          | 0.012235102 |\n",
      "|    reward_min           | -12.263249  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.824       |\n",
      "-----------------------------------------\n",
      "Episode Finished. Sharpe: 0.93\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 35.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 597         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.04557613  |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -16         |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0801     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0619     |\n",
      "|    reward               | -0.11476334 |\n",
      "|    reward_max           | 9.487024    |\n",
      "|    reward_mean          | 0.019030113 |\n",
      "|    reward_min           | -12.340029  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 0.618       |\n",
      "-----------------------------------------\n",
      "\n",
      "3. Preparando Test Q1 2025...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (3160, 8)\n",
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n",
      "Corriendo simulación sobre 61 días...\n",
      "Episode Finished. Sharpe: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (60, 8)\n",
      "Tus 10 Acciones: 5.50%\n",
      "S&P 500:         -4.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\nicor\\AppData\\Local\\Temp\\ipykernel_35608\\4132561579.py:160: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. TU SELECCIÓN DE ACTIVOS\n",
    "# ==============================================================================\n",
    "my_tickers = [\n",
    "    \"MSFT\", \"JNJ\", \"KO\", \"JPM\", \"CVX\", \n",
    "    \"UNH\", \"PG\", \"DE\", \"WMT\", \"O\"\n",
    "]\n",
    "\n",
    "print(f\"Entrenando con {len(my_tickers)} acciones seleccionadas.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. PREPARACIÓN DE DATOS PARA ENTRENAMIENTO (2015 - 2025)\n",
    "# ==============================================================================\n",
    "print(\"\\n1. Descargando Datos de Entrenamiento (Hasta 2025)...\")\n",
    "# CAMBIO: end_date extendido hasta 2025-01-01\n",
    "df_train = YahooDownloader(start_date='2015-01-01', \n",
    "                           end_date='2025-01-01', \n",
    "                           ticker_list=my_tickers).fetch_data()\n",
    "\n",
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list=['macd', 'rsi_30', 'cci_30', 'dx_30'],\n",
    "                     use_turbulence=True,\n",
    "                     user_defined_feature=False)\n",
    "df_train = fe.preprocess_data(df_train)\n",
    "\n",
    "df_train = df_train.sort_values(['date','tic'], ignore_index=True)\n",
    "df_train.index = df_train.date.factorize()[0]\n",
    "\n",
    "# Covarianzas\n",
    "cov_list = []\n",
    "dates_with_cov = []\n",
    "lookback = 252 \n",
    "unique_dates = df_train.date.unique()\n",
    "\n",
    "print(\"Calculando Covarianzas (Entrenamiento)...\")\n",
    "for i in range(lookback, len(unique_dates)):\n",
    "    current_date = unique_dates[i]\n",
    "    data_lookback = df_train.loc[i-lookback:i, :]\n",
    "    price_lookback = data_lookback.pivot_table(index='date', columns='tic', values='close')\n",
    "    return_lookback = price_lookback.pct_change().dropna()\n",
    "    covs = return_lookback.cov().values \n",
    "    cov_list.append(covs)\n",
    "    dates_with_cov.append(current_date)\n",
    "\n",
    "df_train_gym = df_train[df_train.date.isin(dates_with_cov)].copy()\n",
    "cov_dict = dict(zip(dates_with_cov, cov_list))\n",
    "df_train_gym['cov_list'] = df_train_gym['date'].map(cov_dict)\n",
    "df_train_gym = df_train_gym.sort_values(['date', 'tic'], ignore_index=True)\n",
    "df_train_gym.index = df_train_gym.date.factorize()[0]\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. ENTRENAR EL AGENTE\n",
    "# ==============================================================================\n",
    "print(\"\\n2. Entrenando Nuevo Modelo...\")\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": len(my_tickers), \n",
    "    \"stock_dim\": len(my_tickers), \n",
    "    \"tech_indicator_list\": ['macd', 'rsi_30', 'cci_30', 'dx_30'], \n",
    "    \"action_space\": len(my_tickers), \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"risk_free_rate\": 0.0375 \n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df=df_train_gym, **env_kwargs)\n",
    "agent = DRLAgent(env=e_train_gym)\n",
    "\n",
    "model_custom = agent.get_model(\"ppo\", model_kwargs = {\"ent_coef\": 0.01, \"n_steps\": 2048})\n",
    "# Puedes aumentar los timesteps si tienes más datos ahora\n",
    "trained_custom = agent.train_model(model=model_custom, \n",
    "                                   tb_log_name=\"ppo_custom_2025\",\n",
    "                                   total_timesteps=50000)\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. PREPARAR DATOS DE PRUEBA (Q1 2025)\n",
    "# ==============================================================================\n",
    "print(\"\\n3. Preparando Test Q1 2025...\")\n",
    "\n",
    "# CAMBIO: Descargamos desde 2024 para tener los 252 días previos al 1 de Enero de 2025\n",
    "# Si descargáramos desde 2025-01-01, el código fallaría por falta de histórico para covarianza.\n",
    "df_test = YahooDownloader(start_date='2024-01-01', \n",
    "                          end_date='2025-04-05', # Un poco más allá de Abril para asegurar datos\n",
    "                          ticker_list=my_tickers).fetch_data()\n",
    "\n",
    "df_test = fe.preprocess_data(df_test)\n",
    "df_test = df_test.sort_values(['date','tic'], ignore_index=True)\n",
    "df_test.index = df_test.date.factorize()[0]\n",
    "\n",
    "# Covarianzas Test\n",
    "cov_list_test = []\n",
    "dates_test = []\n",
    "unique_dates_test = df_test.date.unique()\n",
    "\n",
    "for i in range(lookback, len(unique_dates_test)):\n",
    "    current_date = unique_dates_test[i]\n",
    "    data_lookback = df_test.loc[i-lookback:i, :]\n",
    "    price_lookback = data_lookback.pivot_table(index='date', columns='tic', values='close')\n",
    "    return_lookback = price_lookback.pct_change().dropna()\n",
    "    covs = return_lookback.cov().values \n",
    "    cov_list_test.append(covs)\n",
    "    dates_test.append(current_date)\n",
    "\n",
    "df_test_gym = df_test[df_test.date.isin(dates_test)].copy()\n",
    "\n",
    "# CAMBIO: FILTRO EXACTO PARA Q1 2025\n",
    "df_test_gym = df_test_gym[(df_test_gym.date >= '2025-01-01') & (df_test_gym.date <= '2025-04-01')]\n",
    "\n",
    "cov_dict_test = dict(zip(dates_test, cov_list_test))\n",
    "df_test_gym['cov_list'] = df_test_gym['date'].map(cov_dict_test)\n",
    "df_test_gym = df_test_gym.sort_values(['date', 'tic'], ignore_index=True)\n",
    "df_test_gym.index = df_test_gym.date.factorize()[0]\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. EJECUTAR BACKTEST\n",
    "# ==============================================================================\n",
    "print(f\"Corriendo simulación sobre {len(df_test_gym.index.unique())} días...\")\n",
    "\n",
    "env_test = StockPortfolioEnv(df=df_test_gym, **env_kwargs)\n",
    "obs, _ = env_test.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action, _states = trained_custom.predict(obs, deterministic=True)\n",
    "    obs, rewards, done, truncated, info = env_test.step(action)\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. COMPARACIÓN Y GRÁFICO\n",
    "# ==============================================================================\n",
    "df_res = pd.DataFrame(env_test.asset_memory)\n",
    "df_res.columns = ['account_value']\n",
    "df_res['date'] = env_test.date_memory\n",
    "df_res['daily_return'] = df_res['account_value'].pct_change()\n",
    "df_res['cum_return'] = (1 + df_res['daily_return']).cumprod()\n",
    "\n",
    "# CAMBIO: Benchmark para 2025\n",
    "bench = YahooDownloader(start_date='2025-01-01', end_date='2025-04-01', ticker_list=['^GSPC']).fetch_data()\n",
    "bench = bench.sort_values('date')\n",
    "bench = bench[bench.date.isin(df_res.date.unique())]\n",
    "bench['cum_return'] = (1 + bench['close'].pct_change().fillna(0)).cumprod()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df_res['date'], df_res['cum_return'], label='Mi Portafolio (10 Stocks)', color='blue', linewidth=2)\n",
    "plt.plot(df_res['date'][:len(bench)], bench['cum_return'], label='S&P 500', color='gray', linestyle='--')\n",
    "plt.title('Estrategia Personalizada vs S&P 500 (Q1 2025)', fontsize=16)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "final_perf = (df_res['cum_return'].iloc[-1] - 1) * 100\n",
    "bench_perf = (bench['cum_return'].iloc[-1] - 1) * 100\n",
    "\n",
    "print(f\"Tus 10 Acciones: {final_perf:.2f}%\")\n",
    "print(f\"S&P 500:         {bench_perf:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finrl_portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
